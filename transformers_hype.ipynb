{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transformers: hype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/nlp_before.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План занятий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ЧБДТ: Что Было До Трансформеров\n",
    "   1. При чём тут нейро-лингвистическое программирование?\n",
    "   2. Почему вектора?\n",
    "   3. Счётные методы: CountVectorizer, TF-IDF, добавляем контекст \n",
    "   4. Дистрибутивная семантика: Word2vec, FastText\n",
    "   5. Рекуррентные нейронные сети: LSTM, GRU\n",
    "### 2. Трансформеры: база\n",
    "   1. Мотивация\n",
    "   2. Attention из all you need?: виды attention, интуиция, реализация\n",
    "   3. Архитектура Transformer: эмбеддинги, энкодер, декодер\n",
    "### 3. Трансформеры: на волне хайпа\n",
    "   1. BERT\n",
    "   2. GPT\n",
    "   3. T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer: архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходно Transformer - Encoder-Decoder архитектура для seq2seq задач (машинного перевода)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи в NLP бывают разные, для многих задач архитектура Encoder-Decoder избыточна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим три основных семейства моделей:\n",
    "- Encoder (BERT-family) - NLU (natural language understanding) задачи\n",
    "- Decoder (GPT-family) - NLG (natural language generation) задачи \n",
    "- Encoder-Decoder (T5 & co.) - Text2Text задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/transformer-arch.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две стадии: pretraining + finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT: Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT - encoder-only transformer. Основная задача: генерировать контекстуализированные эмбеддинги для слов и предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы прошлых моделей:\n",
    "- Омонимия - значения слов зависят от контекста\n",
    "- Out-of-vocabulary слова - новые/редкие слова, опечатки\n",
    "- \"Статичность\" эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/bert_embeddings.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея из word2vec: получить знания о структуре и смысле языка, используя огромные массивы неразмеченных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже на CBOW подход из word2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/cbow.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные отличия - учитываем связь между словами и весь контекст предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: предсказать слово, которое было скрыто маской на основе всего контекста предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн:\n",
    "- Выбираем 15% токенов\n",
    "  - в 80% случаев заменяем на токен [MASK]\n",
    "  - в 10% случаев заменяем на рандомный\n",
    "  - в 10% случаев оставляем без изменений\n",
    "- Предсказываем, какой токен был заменен\n",
    "  - Классификация по всему словарю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/mlm.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next sentence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме эмбеддингов слов, мы также получить хороший эмбеддинг предложения. Можно просто усреднить (как мы делали для word2vec), но всегда ли усреднять хорошо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача - предсказать, идут ли предложения друг за другом в тексте?\n",
    "- Предсказание делается от специального токена [CLS]\n",
    "- Предложения разделены специальным токеном [SEP]\n",
    "- 50% предложения следуют друг за другом\n",
    "- 50% предложения независимы (выбираем случайное из выборки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/nsp.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доучиваем модельку под различные задачи на небольших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification\n",
    "  - Sentence-pair or single sentence\n",
    "- Sequence labelling (NER)\n",
    "- Text segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/bert-tasks.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три типа токенов:\n",
    "- Позиционные эмбеддинги - для учета порядка слов\n",
    "- Эмбеддинги сегментов - для разделения предложений\n",
    "- Эмбеддинги токенов - привычный слой эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/bert_tokenization.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А в остальном - буквально тот же самый энкодер из Transformer'a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Семейка BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Модель</th>\n",
    "    <th>Саммари</th>\n",
    "    <th>Описание</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>BERT</td>\n",
    "    <td>База</td>\n",
    "    <td>Задачи:<br>- MLM (static masking)<br>- NSP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RoBERTa</td>\n",
    "    <td>Улучшенный процесс обучения</td>\n",
    "    <td>Особенности:<br>- Ооочень много данных (160Gb vs 16Gb)<br>- Большой размер батча (8000 vs 256)<br><br>Задачи:<br>- MLM (dynamic masking)<br>- No NSP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Electra</td>\n",
    "    <td>Улучшенный процесс обучения</td>\n",
    "    <td>Особенности:<br>- Тренинг на всех данных, а не только маскированных<br><br>Задачи:<br>- Replaced token detection (instead of MLM)<br>- No NSP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Albert</td>\n",
    "    <td>Облегченный BERT</td>\n",
    "    <td>Особенности:<br>- Шэринг параметров между слоями (FF / FF+MHA / MHA)<br>- Факторизация эмбеддингов<br><br>Задачи:<br>- MLM<br>- SOP (sentence order prediction)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DistillBERT &amp; TinyBERT</td>\n",
    "    <td>Маленькие BERT'ы, полученные за счет дистилляции</td>\n",
    "    <td>Особенности:<br>- DistillBERT учится предсказывать предсказания большого BERT<br>- TinyBERT учится предсказывать в т.ч. промежуточные слои <img src=\"attachements/third/distill_vs_tiny.png\" width=\"500\"/> </td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT: Generative pre-trained transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling - задача предсказания следующего токена (слова / подслова / буквы) в предложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути - генерация текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры:\n",
    "- Написание контента - сказок, рассказов, рекламных текстов\n",
    "- Автодополнение (кода, поискового запроса, текста)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt-2-autoregression.gif\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT - decoder-only transformer, задача которого - авторегрессионно генерировать следущее слово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хитрости и особенности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Очень много текстов\n",
    "- Очень (ОЧЕНЬ!) большие модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt_size.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эмерджентность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большие модели с большими данными обретают новые свойства: учатся решать задачи, которым специально не учились: перевод, ответы на вопросы, NER, сегментация текста, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И их больше не нужно файнтюнить!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как заставить модель понять, что от неё нужно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zero-shot - просто попроси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/zero_shot.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-shot - покажи пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/one_shot.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Few-shot - покажи несколько примеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/few_shot.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество возрастает при увеличении модели и количества примеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt_few_shot.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество на отдельных задачах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель показывает себя очень хорошо либо даже опережает специализированные SOTA решения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LAMBADA - нужно предсказать последнее слово в предложении. (нужно улавливать глобальный контекст)\n",
    "- StoryCloze - нужно выбрать верное окончание истории из четырех вариантов.\n",
    "- HellaSwag - NLI датасет; нужно выбрать логически подходящее завершение текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt_pqrformance.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt-Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ещё можно добиться, чтобы модель делала то, что вы от неё хотите?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/prompt_engineering.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор \"затравки\" - очень мощный инструмент. Моделями можно манипулировать!\n",
    "- Я дам тебе 200 долларов чаевыми, если ты мне поможешь\n",
    "- Let's think step-by-step\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/prompt_tuning.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас - это уже целый мир, всё ограничивается только фантазией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодим!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LR = 1e-5\n",
    "VERBOSE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\").to(DEVICE)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    return tokenizer(texts, return_attention_mask=True, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, do_sample=False, **kwargs):\n",
    "    tokens = tokenize(prompt)\n",
    "    out_tokens = model.generate(**tokens, do_sample=do_sample, **kwargs)\n",
    "\n",
    "    return tokenizer.batch_decode(out_tokens, ignore_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Шел медведь по лесу,\\n'\n",
      " '\\t\\t\\t\\xa0И вдруг увидел он: в небе над лесом — звезда. \\n'\n",
      " '      И сказал ему зверь-громовержец; «Ты видишь звезду?» Он ответил так же '\n",
      " 'и воскликнул с небес громоподобным голосом (в переводе на русский язык это '\n",
      " 'звучит как \"звезда\"). Медведь поднял голову вверх к небу… А потом стал '\n",
      " 'кричать во все горло... Но не мог остановиться ни один из зверей! Тогда царь '\n",
      " 'приказал убить его ударом меча!.. В тот день молния ударила прямо между '\n",
      " 'ними... Они упали замертво от страха перед грозой...\" [1] - Ср.: http://www2')\n"
     ]
    }
   ],
   "source": [
    "pprint(generate(\"Шел медведь по лесу\", max_length=128, repetition_penalty=2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/anecdotes.json\") as file:\n",
    "    anecdotes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39636"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anecdotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "anecdote_tokens = tokenizer(anecdotes, max_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.Series(list(map(len, anecdote_tokens[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39636.000000\n",
       "mean       118.387552\n",
       "std        178.214457\n",
       "min          5.000000\n",
       "50%         63.000000\n",
       "95%        369.000000\n",
       "99%        879.650000\n",
       "max       2048.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe(percentiles=[0.5, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdotes = [anecdotes[i] for i in lengths[lengths < 350].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdotes = sorted(anecdotes, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-Ало, это Алена?\\n-Да\\n-ст', 'Узбек-людоед съел пловца']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anecdotes[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnecdoteDataset(Dataset):\n",
    "    def __init__(self, anecdotes) -> None:\n",
    "        self.anecdotes = anecdotes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.anecdotes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.anecdotes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anecdote_collate(batch):\n",
    "    return tokenize(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdote_dataset = AnecdoteDataset(anecdotes)\n",
    "anecdote_dataloader = DataLoader(anecdote_dataset, batch_size=10, shuffle=False, collate_fn=anecdote_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,     0,     0,     0,     0,     0,  1140, 11512,   448, 37960,\n",
       "           367, 15393,     5],\n",
       "        [   17,   618,   435,    16,   481, 24818,    35,   203,    17,  4529,\n",
       "           203,    17,   285],\n",
       "        [    0,     0,     0,  1140,   288, 10810,    17,   623,   660,   383,\n",
       "         37284, 38607,   613],\n",
       "        [    0,     0,     0,    17,  1140,  1304,  8294, 23647,    35,   203,\n",
       "            17,  4529,    18],\n",
       "        [    0,     0,     0,     0,     0,   822, 20681,  4527,   802,   282,\n",
       "          3808,   476,    18],\n",
       "        [    0,     0,     0,     0,     0,     0,  6115,  1496,  7999, 40571,\n",
       "           309, 32679,     8],\n",
       "        [    0,     0,    17,   548,   374,    16,  9160,   356,  6036,    35,\n",
       "           203,    17,   347],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,  2997,   798,\n",
       "          6249, 26133,  4038],\n",
       "        [    0,     0,     0,  7148,  1594,  4961,    16,   583,   694,   279,\n",
       "           578,   350,    18],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,  5786, 39487,   329,\n",
       "          6032, 26951,     5]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(anecdote_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим:\n",
    "1. Паддинг слева\n",
    "2. Паддится не так много (но можно и меньше: как?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for i, input_tokens in enumerate(tqdm(anecdote_dataloader, total=len(anecdote_dataloader))):\n",
    "        input_tokens = input_tokens.to(DEVICE)\n",
    "\n",
    "        labels = input_tokens[\"input_ids\"].clone()\n",
    "        labels[labels == 0] = -100  # to ignore them when computing loss\n",
    "        \n",
    "        loss = model(\n",
    "            **input_tokens,\n",
    "            labels=labels,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if (i + 1) % VERBOSE == 0:\n",
    "            print(f\"Step {i + 1}: loss - {sum(losses[-VERBOSE:-1]) / VERBOSE}\")\n",
    "            model.eval()\n",
    "            print(generate(\"Шел медведь по лесу\", repetition_penalty=2.5, max_length=128))\n",
    "            model.train()\n",
    "\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "\n",
    "    print(f\"EPOCH {epoch} - epoch loss: {(epoch_loss):3f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/3742 [00:06<38:31,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: loss - 5.33553729057312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3742 [00:09<1:24:58,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шел медведь по лесу,\n",
      "\tИ в лес он не пошел. И на медведя-то никто и внимания бы ему такоого! А тут — бац… — а там уже все равно: «Батюшки!» Ну что ж? Не повезло тебе с медведем!.. Вот ты теперь кто?..» (Анекдот) \n",
      "      - Да я же тебя знаю... Ты мне как брат родной.. Я ведь тоже из Москвы приехал к вам за тобой приехать.... Так вот у меня есть друг детства -- это мой двоюродный дед Иван Иванович Шаповалов. Он живет сейчас во Франции, но мы его\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/3742 [00:14<39:00,  1.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: loss - 5.191372299194336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/3742 [00:17<1:23:43,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шел медведь по лесу,\n",
      "\t\t\t — и в лес пошел. — И сказал: «Я не пойду!» А я ему говорю… Он говорит мне так-то! Я его люблю!.. Ну вот что значит любовь? Это когда ты любишь человека за то же самое чувство к нему или нет?.. Вот это да!!!!! Да он меня любит... а потом еще спрашивает про тебя... ))))))))) \n",
      "       -А как вы думаете? – спросил у него котенок с улицы.— Как бы вам объяснить,что такое Любовь?!– ответил Котёнок.-Любовь есть такая штука которая называется \"любовь\". Ты знаешь\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/3742 [00:23<40:38,  1.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30: loss - 5.076394414901733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/3742 [00:26<1:25:13,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шел медведь по лесу,\n",
      "\t\t\t — и в лес пошел. — И сказал: «Я не пойду!» А я ему говорю… Ты что? Я же тебя люблю! Ну-ка иди сюда!.. Иди ко мне на колени!!!  \n",
      "        - Да ты чего?! – заорал он так громко... а потом вдруг стал кричать еще громче..и все вокруг засмеялись....а у меня глаза стали красные от слез!!я заплакала!!!!А когда увидела его лицо с красными глазами то поняла,что это мой муж! Он был очень красивый мужчина.Он любил свою жену!!!И теперь она будет любить всех мужчин мира!!!!!!!!))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 39/3742 [00:32<39:15,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40: loss - 4.868323230743409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 40/3742 [00:35<1:25:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шел медведь по лесу.\n",
      "- А ты? - спросил я, когда мы вышли из леса и пошли к реке на берег реки...  \n",
      "       Я не знаю как это назвать! Но мне кажется что у меня есть имя: \"Мяу\". И оно звучит так : Мяукаюуу!!! :)    Оригинал записи находится здесь.         Посмотреть обсуждение этой заметки с помощью приложения LiveJournal для Android можно тут или там..                 Серия сообщений СЛОВАРИКИ Часть 1 — Как сделать селфиЧасть 2— Что такое «Слоник»?.. (с)Котенок в сапогах…(c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 49/3742 [00:40<40:45,  1.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50: loss - 4.975189352035523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 50/3742 [00:44<1:26:25,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шел медведь по лесу.\n",
      "- А ты? - спросил я, когда мы вышли из леса и пошли к реке в сторону города... \n",
      "  Я не знаю как это называется! Но мне кажется что у меня есть имя: \"Мяу\". И оно звучит так : Мяукающий Медведь!!! :) Это значит мяукал котенок или нет?!:) Ну а если да то почему он такой маленький???)))А вы знаете кто такие мЯУКИ??!!))Имя такое же красивое..)Котёнок с большой мордочкой....и хвостом))))Сразу видно кота!!!!Это мой любимый котик(с\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 59/3742 [00:52<1:04:26,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 60: loss - 4.4125970840454105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 60/3742 [00:55<1:43:16,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шел медведь по лесу.\n",
      "- А ты? - спросил он, когда я вышел из леса и сел на землю рядом с ним в траву.- Я!  \n",
      "       И что же это за зверь такой?- спросила она меня: \"А вот этот!\"Я ответил:\"Да\".Она засмеялась:- Даааа... Это мой котенок!- Она посмотрела мне прямо глаза,- а у тебя есть кошка?!\"Котёнок?\"-\"Нет.\"И тут котик сказал ей :\"-Угу...\"и мы пошли к ней домой...Мы её звали Клошадка....она была очень красивая!!!Попросила кота принести нам\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 68/3742 [01:00<54:35,  1.12it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb Cell 99\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_epoch(\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb Cell 99\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minput_tokens,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     labels\u001b[39m=\u001b[39mlabels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/transformers_hype.ipynb#Y252sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## температура и разные другие параметры генерации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5: Transfer learning in all its glory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что если объединить BERT и GPT и решать оооочень много различных задач?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получится T5 - Encoder-Decoder transformer, предназначенный для решения text2text задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно представлять различные задачи в виде Text2text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/t5_multitask.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти как BERT, только сложнее: маскируем последовательности слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/t5_pretraining.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи:\n",
    "- Перевод - переводим с одного языка на другой.\n",
    "- Суммаризация - делаем краткий пересказ текста.\n",
    "- Question answering - отвечаем на вопрос по тексту.\n",
    "- Классификация текстов - относим текст к какой-то группе.\n",
    "- Генерация текстов - сочиняем (продолжаем) текст.\n",
    "- Регрессия по текстам - предсказываем число по тексту (анализ тональности, возраст, ...). \n",
    "- NLI (Natural language inference) - понимаем логическую связь предложений: продолжает, отрицает или не связано.\n",
    "- Сегментация текстов - находим отрезки текста, где что-то важное нам происходит (аспектный анализ тональности, ответ на вопрос, ...)\n",
    "\n",
    "*(Т5 училась не на все эти задачи, некоторые просто как пример.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/t5_tasks.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder vs Decoder-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Но ведь GPT умеет делать то же самое!\n",
    "- Да, что-то из этого может и BERT делать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/transformer-arch.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-only\n",
    "\n",
    "Всякие BERT, RoBERTa and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любые NLU-only задачи:\n",
    "- Text Classification\n",
    "- Sequence labelling\n",
    "- Sentiment analysis\n",
    "- NLI\n",
    "- QA\n",
    "- Search & Recommender systems (спойлер!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder-only\n",
    "\n",
    "Всякие GPT, XLNet and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любые чисто генеративные задачи:\n",
    "- Text completion\n",
    "- Text generation\n",
    "- Creative writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И задачи, где не требуется глубокое понимание:\n",
    "- диалоговые системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-Decoder\n",
    "\n",
    "Всякие Transformer, BART, T5 and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи на понимание + генерацию:\n",
    "- Machine translation\n",
    "- Summarization\n",
    "- QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реальность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем ChatGPT и погнали..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
