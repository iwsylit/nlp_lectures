{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transformers: hype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/nlp_before.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План занятий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ЧБДТ: Что Было До Трансформеров\n",
    "   1. При чём тут нейро-лингвистическое программирование?\n",
    "   2. Почему вектора?\n",
    "   3. Счётные методы: CountVectorizer, TF-IDF, добавляем контекст \n",
    "   4. Дистрибутивная семантика: Word2vec, FastText\n",
    "   5. Рекуррентные нейронные сети: LSTM, GRU\n",
    "### 2. Трансформеры: база\n",
    "   1. Мотивация\n",
    "   2. Attention из all you need?: виды attention, интуиция, реализация\n",
    "   3. Архитектура Transformer: эмбеддинги, энкодер, декодер\n",
    "### 3. Трансформеры: на волне хайпа\n",
    "   1. BERT: pre-training, fine-tuning, семейка\n",
    "   2. GPT: language modelling, n-shot, prompt-engineering, decoding stratetiges\n",
    "   3. T5: multitask models, seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer: архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходно Transformer - Encoder-Decoder архитектура для seq2seq задач (машинного перевода)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи в NLP бывают разные, для многих задач архитектура Encoder-Decoder избыточна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим три основных семейства моделей:\n",
    "- Encoder (BERT-family) - NLU (natural language understanding) задачи\n",
    "- Decoder (GPT-family) - NLG (natural language generation) задачи \n",
    "- Encoder-Decoder (T5 & co.) - Text2Text задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/transformer-arch.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две стадии: pretraining + finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT: Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT - encoder-only transformer. Основная задача: генерировать контекстуализированные эмбеддинги для слов и предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы прошлых моделей:\n",
    "- Омонимия - значения слов зависят от контекста\n",
    "- Out-of-vocabulary слова - новые/редкие слова, опечатки\n",
    "- \"Статичность\" эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/bert_embeddings.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея из word2vec: получить знания о структуре и смысле языка, используя огромные массивы неразмеченных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже на CBOW подход из word2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/cbow.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные отличия - учитываем связь между словами и весь контекст предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: предсказать слово, которое было скрыто маской на основе всего контекста предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн:\n",
    "- Выбираем 15% токенов\n",
    "  - в 80% случаев заменяем на токен [MASK]\n",
    "  - в 10% случаев заменяем на рандомный\n",
    "  - в 10% случаев оставляем без изменений\n",
    "- Предсказываем, какой токен был заменен\n",
    "  - Классификация по всему словарю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/mlm.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next sentence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме эмбеддингов слов, мы также получить хороший эмбеддинг предложения. Можно просто усреднить (как мы делали для word2vec), но всегда ли усреднять хорошо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача - предсказать, идут ли предложения друг за другом в тексте?\n",
    "- Предсказание делается от специального токена [CLS]\n",
    "- Предложения разделены специальным токеном [SEP]\n",
    "- 50% предложения следуют друг за другом\n",
    "- 50% предложения независимы (выбираем случайное из выборки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/nsp.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доучиваем модельку под различные задачи на небольших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно предложение - определяем тональность, токсичность или тематику текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пара предложений - определяем связь между предложениями. Например, подходит ли кандидат на вакансию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLI - Natural Language Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понимаем логическую связь предложений: продолжает, отрицает или не связано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/nli_task.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо классифицировать каждый токен в предложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая частая задача - Named Entity Recognition. Иногда использую как нарицательное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/ner_task.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача - выделить границы интересующего нас сегмента текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/text_segmentation.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как учим BERT на эти задачи?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/bert-tasks.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три типа токенов:\n",
    "- Позиционные эмбеддинги - для учета порядка слов\n",
    "- Эмбеддинги сегментов - для разделения предложений\n",
    "- Эмбеддинги токенов - привычный слой эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/bert_tokenization.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А в остальном - буквально тот же самый энкодер из Transformer'a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Семейка BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Модель</th>\n",
    "    <th>Саммари</th>\n",
    "    <th>Описание</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>BERT</td>\n",
    "    <td>База</td>\n",
    "    <td>Задачи:<br>- MLM (static masking)<br>- NSP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RoBERTa</td>\n",
    "    <td>Улучшенный процесс обучения</td>\n",
    "    <td>Особенности:<br>- Ооочень много данных (160Gb vs 16Gb)<br>- Большой размер батча (8000 vs 256)<br><br>Задачи:<br>- MLM (dynamic masking)<br>- No NSP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Electra</td>\n",
    "    <td>Улучшенный процесс обучения</td>\n",
    "    <td>Особенности:<br>- Тренинг на всех данных, а не только маскированных<br><br>Задачи:<br>- Replaced token detection (instead of MLM)<br>- No NSP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Albert</td>\n",
    "    <td>Облегченный BERT</td>\n",
    "    <td>Особенности:<br>- Шэринг параметров между слоями (FF / FF+MHA / MHA)<br>- Факторизация эмбеддингов<br><br>Задачи:<br>- MLM<br>- SOP (sentence order prediction)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DistillBERT &amp; TinyBERT</td>\n",
    "    <td>Маленькие BERT'ы, полученные за счет дистилляции</td>\n",
    "    <td>Особенности:<br>- DistillBERT учится предсказывать предсказания большого BERT<br>- TinyBERT учится предсказывать в т.ч. промежуточные слои <img src=\"attachements/third/distill_vs_tiny.png\" width=\"500\"/> </td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### База"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Читаем и готовим датасет - это мы уже видели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dataset.txt\")as file:\n",
    "    data = file.read().split(\"\\n\")[:-1]\n",
    "    data = list(map(lambda x: x.split(\" \", maxsplit=1), data))\n",
    "    data = pd.DataFrame(data, columns=[\"target\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__INSULT</td>\n",
       "      <td>скотина! что сказать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>я сегодня проезжала по рабочей и между домами ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>очередной лохотрон. зачем придумывать очередно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>ретро дежавю ... сложно понять чужое сердце , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>а когда мы статус агрогородка получили?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                                               text\n",
       "0  __label__INSULT                               скотина! что сказать\n",
       "1  __label__NORMAL  я сегодня проезжала по рабочей и между домами ...\n",
       "2  __label__NORMAL  очередной лохотрон. зачем придумывать очередно...\n",
       "3  __label__NORMAL  ретро дежавю ... сложно понять чужое сердце , ...\n",
       "4  __label__NORMAL            а когда мы статус агрогородка получили?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "__label__NORMAL                                       203685\n",
       "__label__INSULT                                        28567\n",
       "__label__INSULT,__label__THREAT                         6317\n",
       "__label__THREAT                                         5460\n",
       "__label__OBSCENITY                                      2245\n",
       "__label__INSULT,__label__OBSCENITY                      1766\n",
       "__label__INSULT,__label__OBSCENITY,__label__THREAT       176\n",
       "__label__OBSCENITY,__label__THREAT                        74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"target\"] \\\n",
    "    .apply(lambda x: \"__label__OBSCENITY\" if \"OBSCENITY\" in x else x) \\\n",
    "    .apply(lambda x: \"__label__THREAT\" if \"THREAT\" in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "__label__NORMAL       203685\n",
       "__label__INSULT        28567\n",
       "__label__THREAT        11777\n",
       "__label__OBSCENITY      4261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).groupby(\"target\").head(6666).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "__label__INSULT       6666\n",
       "__label__NORMAL       6666\n",
       "__label__THREAT       6666\n",
       "__label__OBSCENITY    4261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"target\"].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>это твоя мама толстая все сжирает,а у путьки н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>правда на 100% . прежде чем что то требовать н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>все правильно не уступай трамваю, и поездам то...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>таких людей убивать нужно, бедный ребёнок, сер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>опять театр опять развлекуха!! опять клоуны, а...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  это твоя мама толстая все сжирает,а у путьки н...\n",
       "1       1  правда на 100% . прежде чем что то требовать н...\n",
       "2       0  все правильно не уступай трамваю, и поездам то...\n",
       "3       2  таких людей убивать нужно, бедный ребёнок, сер...\n",
       "4       1  опять театр опять развлекуха!! опять клоуны, а..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    6666\n",
       "1    6666\n",
       "2    6666\n",
       "3    4261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.15, stratify=data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_data[\"text\"].values, test_data[\"text\"].values \n",
    "y_train, y_test = train_data[\"target\"].values, test_data[\"target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Строим модель!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface - главная библиотечка для взаимодействия с трансформерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут есть:\n",
    "- Хаб предобученных моделей\n",
    "- Вспомогательные утилиты для обучения и оценки моделей\n",
    "- И чего только нет..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/huggingface_models.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LR = 1e-4\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берём BERT для классификации последовательностей.\n",
    "\n",
    "Всё, нужное нам, уже инициализированно. Не забываем файн-тюне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=data[\"target\"].nunique())\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизатор и вызов модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 343, 9922, 314, 29852, 314, 24174, 52655, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"я просто в тебя втюрилась\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] я просто в тебя втюрилась [SEP]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2, 343, 9922, 314, 29852, 314, 24174, 52655, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 343, 9922, 314, 29852, 314, 24174, 52655, 3, 14665, 1046, 745, 1232, 47802, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"я просто в тебя втюрилась\", \"потому что дора дура\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] я просто в тебя втюрилась [SEP] потому что дора дура [SEP]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2, 343, 9922, 314, 29852, 314, 24174, 52655, 3, 14665, 1046, 745, 1232, 47802, 3],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   343,  9922,   314, 29852,   314, 24174, 52655,     3],\n",
       "        [    2, 14665,  1046,   745,  1232, 47802,     3,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"я просто в тебя втюрилась\", \"потому что дора дура\"], padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вызов модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0040, -0.0287, -0.0198,  0.0193]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer(\"я просто в тебя втюрилась\", return_tensors=\"pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0040, -0.0287, -0.0198,  0.0193]], grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[-0.0142,  0.0298, -0.0084,  ...,  0.0131,  0.0028,  0.0183],\n",
       "         [-0.9121,  0.3245, -0.3886,  ...,  0.6066,  0.6993, -0.5504],\n",
       "         [ 1.3372,  0.3197, -0.4329,  ..., -0.1644, -0.7971,  0.4067],\n",
       "         ...,\n",
       "         [ 0.9813, -1.7365, -0.0614,  ...,  1.5010, -0.3529,  0.9264],\n",
       "         [-1.0524, -0.9197,  2.0454,  ..., -0.1242, -0.9972,  1.4023],\n",
       "         [ 0.1239, -0.2321, -0.0834,  ..., -0.5896, -1.6422, -0.1138]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0365,  0.1742,  0.2868,  ..., -0.0316,  0.0761, -0.5213],\n",
       "         [-0.5092, -0.2252,  0.0681,  ..., -0.0459,  0.5087, -0.8478],\n",
       "         [ 1.8197, -0.0455, -0.6360,  ...,  0.1347, -0.4981, -0.3415],\n",
       "         ...,\n",
       "         [ 1.4533, -1.4143, -0.2475,  ...,  1.0662,  0.3260,  0.2414],\n",
       "         [-0.8736, -1.2774,  1.3637,  ..., -0.3602, -0.5690,  0.6849],\n",
       "         [-0.1280,  0.4532, -0.2847,  ..., -0.7330, -1.4618, -0.5757]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0362, -0.0964,  0.5477,  ...,  0.0579,  0.0490, -0.8663],\n",
       "         [-0.1399, -1.0107,  0.2562,  ..., -0.4571,  0.1519, -0.6425],\n",
       "         [ 1.9799, -0.6998, -0.1756,  ..., -0.0984, -0.3750, -0.6826],\n",
       "         ...,\n",
       "         [ 2.1012, -0.7931,  0.0287,  ...,  1.2507, -0.2286, -0.0079],\n",
       "         [-0.1905, -0.2854,  1.6610,  ..., -0.2650, -0.0353, -0.4112],\n",
       "         [-0.1095, -0.0556, -0.1186,  ..., -0.1266, -0.1732, -0.2054]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1474, -0.3305,  0.7366,  ..., -0.0997,  0.1295, -0.6596],\n",
       "         [ 0.1103, -0.5991,  0.3884,  ...,  0.2523,  0.2593, -1.0205],\n",
       "         [ 1.2611, -0.1888, -0.0525,  ...,  0.3010, -0.4371, -0.2150],\n",
       "         ...,\n",
       "         [ 0.8369,  0.0415,  0.3670,  ...,  1.5317, -0.1007, -0.1338],\n",
       "         [ 0.0334,  0.2868,  1.3768,  ..., -0.9609,  0.0627, -0.0455],\n",
       "         [ 0.1116, -0.7054,  0.3988,  ..., -0.2269,  0.8960, -0.3280]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer(\"я просто в тебя втюрилась\", return_tensors=\"pt\"), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(1.3762, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0040, -0.0287, -0.0198,  0.0193]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer(\"я просто в тебя втюрилась\", return_tensors=\"pt\"), labels=torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Датасет и даталоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    texts = list(map(itemgetter(0), batch))\n",
    "    labels = list(map(itemgetter(1), batch))\n",
    "\n",
    "    tokens = tokenizer(texts, return_tensors=\"pt\", max_length=64, padding=\"max_length\", truncation=True)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BertDataset(X_train, y_train)\n",
    "test_dataset = BertDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тренинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(y_true, y_pred, average='macro'):\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "\n",
    "    print(f'{average.capitalize()} Precision = {precision:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}')\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for tokens, labels in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        tokens = tokens.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        loss = model(**tokens, labels=labels).loss\n",
    "\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_epoch():\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    for tokens, labels in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        tokens = tokens.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(**tokens, labels=labels)\n",
    "\n",
    "        pred_labels = outputs.logits.argmax(dim=1).tolist()\n",
    "\n",
    "        predictions.extend(pred_labels)\n",
    "        losses.append(outputs.loss.item())\n",
    "\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    \n",
    "    return epoch_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_epoch()\n",
    "        test_loss, pred_test = test_epoch()\n",
    "\n",
    "        print(f\"TRAIN Epoch {epoch+1}, Loss: {train_loss:.4f}\")\n",
    "        print(f\"TEST Epoch {epoch+1}, Loss: {test_loss:.4f}\")\n",
    "\n",
    "        compute_metrics(y_test, pred_test)\n",
    "        print()\n",
    "    \n",
    "    return pred_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [01:52<00:00,  1.44it/s]\n",
      "100%|██████████| 29/29 [00:04<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 1, Loss: 0.6297\n",
      "TEST Epoch 1, Loss: 0.3823\n",
      "Macro Precision = 0.8616, Recall = 0.8667, F1 = 0.8632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [01:55<00:00,  1.40it/s]\n",
      "100%|██████████| 29/29 [00:06<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 2, Loss: 0.2938\n",
      "TEST Epoch 2, Loss: 0.3350\n",
      "Macro Precision = 0.8824, Recall = 0.8756, F1 = 0.8784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [02:00<00:00,  1.35it/s]\n",
      "100%|██████████| 29/29 [00:05<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 3, Loss: 0.1888\n",
      "TEST Epoch 3, Loss: 0.3361\n",
      "Macro Precision = 0.8814, Recall = 0.8812, F1 = 0.8809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT: Generative pre-trained transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling - задача предсказания следующего токена (слова / подслова / буквы) в предложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути - генерация текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры:\n",
    "- Написание контента - сказок, рассказов, рекламных текстов\n",
    "- Автодополнение (кода, поискового запроса, текста)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt-2-autoregression.gif\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT - decoder-only transformer, задача которого - авторегрессионно генерировать следущее слово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хитрости и особенности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Очень много текстов\n",
    "- Очень (ОЧЕНЬ!) большие модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt_size.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эмерджентность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большие модели с большими данными обретают новые свойства: учатся решать задачи, которым специально не учились: перевод, ответы на вопросы, NER, сегментация текста, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И их больше не нужно файнтюнить!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как заставить модель понять, что от неё нужно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zero-shot - просто попроси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/zero_shot.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-shot - покажи пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/one_shot.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Few-shot - покажи несколько примеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/few_shot.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество возрастает при увеличении модели и количества примеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt_few_shot.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество на отдельных задачах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель показывает себя очень хорошо либо даже опережает специализированные SOTA решения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LAMBADA - нужно предсказать последнее слово в предложении. (нужно улавливать глобальный контекст)\n",
    "- StoryCloze - нужно выбрать верное окончание истории из четырех вариантов.\n",
    "- HellaSwag - NLI датасет; нужно выбрать логически подходящее завершение текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/gpt_pqrformance.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt-Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ещё можно добиться, чтобы модель делала то, что вы от неё хотите?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/prompt_engineering.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор \"затравки\" - очень мощный инструмент. Моделями можно манипулировать!\n",
    "- Я дам тебе 200 долларов чаевыми, если ты мне поможешь\n",
    "- Let's think step-by-step\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/prompt_tuning.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас - это уже целый мир, всё ограничивается только фантазией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Читаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = 5\n",
    "BATCH_SIZE = 5\n",
    "LR = 5e-5\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50264, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    return tokenizer(texts, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, do_sample=False, **kwargs):\n",
    "    tokens = tokenize(prompt).to(DEVICE)\n",
    "    out_tokens = model.generate(**tokens, do_sample=do_sample, **kwargs)\n",
    "\n",
    "    return tokenizer.batch_decode(out_tokens, ignore_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу,\\n\\t\\tИ вдруг увидел он, что в лесу\\n\\t\\t']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Шел медведь по лесу\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Читаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/anecdotes.json\") as file:\n",
    "    anecdotes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39636"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anecdotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Включил я как-то Вечерний ургант выпуск 1290 от 17.04.2020 (на 15:00), а там армяне в нарды играют'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anecdotes[456]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чистим немножечко"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdotes = list(map(lambda x: re.sub(r\"[\\n\\-\\_\\.]+\\n\", \"\\n\", x), anecdotes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизируем немножечко"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "anecdote_tokens = tokenizer(anecdotes, max_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.Series(list(map(len, anecdote_tokens[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39636.000000\n",
       "mean       116.122944\n",
       "std        176.377865\n",
       "min          2.000000\n",
       "50%         61.000000\n",
       "95%        365.000000\n",
       "99%        866.000000\n",
       "max       2048.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe(percentiles=[0.5, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39636"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anecdotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdotes = [anecdotes[i] for i in lengths[(lengths < 350) & (lengths > 4)].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортируем, чтобы делать меньше паддингов и лишних вычислений.\n",
    "\n",
    "Мы так уже делали, когда учили LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdotes = sorted(anecdotes, key=lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Узбек-людоед съел пловца', '-У вас хлеб свежий?\\n-Да.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anecdotes[-30:-28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет ни GPUшки, ни бесконечности времени..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdotes = anecdotes[20000:20100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Датасет и даталоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnecdoteDataset(Dataset):\n",
    "    def __init__(self, anecdotes) -> None:\n",
    "        self.anecdotes = anecdotes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.anecdotes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.anecdotes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anecdote_collate(batch):\n",
    "    return tokenize(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "anecdote_dataset = AnecdoteDataset(anecdotes)\n",
    "anecdote_dataloader = DataLoader(anecdote_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=anecdote_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### А что там в этом батче?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,    17,   563, 28506,  4351,   481,  2309, 32397,   432, 11548,\n",
       "           541,  5981,    16,  7970, 20063, 43756,   291,   289, 21208,   225,\n",
       "           203,    17,  9230,  2309,    35,  9398, 34210,    35, 47752,   280,\n",
       "            16,   428,   694,  7757,   282,  2218,   914, 32225],\n",
       "        [    0,     0,     0,     0,   983,  4194,  8327, 17398, 17889,  3417,\n",
       "         12380,    30,   203, 45652,  2796,   289,   727,  2679,   297,  4351,\n",
       "          6858,   309,  7812,    16,   515,   457,  1849,   448, 16823,   475,\n",
       "         44927,   414,    16,   289, 11900,  2796,  3619, 19926,   334, 13503,\n",
       "            16,   367,   727,  2679,   297,  4351,   384, 18758,   673,   272,\n",
       "           203,  1009,   262,  3484,  1514,  1483,   436,  1960],\n",
       "        [   17,   629, 44098, 10989,   299, 18025,  2688,  9880,   356,    16,\n",
       "         26746,    17,   361,    18,   225,   203,    17,   439,   428,  1337,\n",
       "         19387,  3359, 29350, 10989,   299,  6420,   637, 13407,    17,  2997,\n",
       "           350,   313, 23088,    17,   361,    35,   225,   203,    17, 39099,\n",
       "           315,    18, 37482,    16,   417,  1304,  1783,   292,   268,    93,\n",
       "            16,  1055, 16433,  2254,   484, 21845, 15599,    35],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0, 49762,  8147,  1272, 29537,    30,   203,    17,  1714,   357,\n",
       "            16,   367,   694,  4515,    16,   374,  8942,   281, 35743, 16140,\n",
       "           376,  1001,   347,  2423,    35,   203,    17,  1591, 28025,    16,\n",
       "          3176,   986,   505,   352,  1219,    16,   367,   322,  2946,    16,\n",
       "           374,   492, 34936,   424, 19845, 16791,   305,     5],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0, 12134,  4749, 10956,   294,  6527,  1205,  2158,   289,\n",
       "           678, 26133,   360,  1047,   473,   404,   431, 30931, 22085,    13,\n",
       "          5284,   281, 18627,  2158,   203,  1009,   262, 21624,   309,  2089,\n",
       "          6266,    18,   629,   282,  1315, 12236,    16,  1607,  3841,     5,\n",
       "           203,   992, 29977,   694, 29726, 21350,   266,  1368]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(anecdote_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим:\n",
    "1. Паддинг слева\n",
    "2. Паддится не так много (но можно и меньше: как?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for i, input_tokens in enumerate(tqdm(anecdote_dataloader, total=len(anecdote_dataloader))):\n",
    "        input_tokens = input_tokens.to(DEVICE)\n",
    "\n",
    "        labels = input_tokens[\"input_ids\"].clone()\n",
    "        labels[labels == 0] = -100  # to ignore them when computing loss\n",
    "        \n",
    "        loss = model(\n",
    "            **input_tokens,\n",
    "            labels=labels,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if (i + 1) % VERBOSE == 0:\n",
    "            print(f\"Step {i + 1}: loss - {sum(losses[-VERBOSE:-1]) / VERBOSE}\")\n",
    "            model.eval()\n",
    "            print(generate(\"Шел медведь по лесу\"))\n",
    "            model.train()\n",
    "\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "\n",
    "    print(f\"EPOCH {epoch} - epoch loss: {(epoch_loss):3f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:03<00:14,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: loss - 3.9486947059631348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:04<00:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу.  Он увидел, что на дереве сидит медведь.  Он схватил его']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:08<00:09,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: loss - 3.5228697776794435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:09<00:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу. \\n- А ты знаешь, что он сказал?\\n- А']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:12<00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: loss - 3.204625463485718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:13<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу. \\n- А ты знаешь, что такое медведь?\\n- А']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:17<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: loss - 3.375677061080933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу.  Вдруг видит: на дереве сидит медведь. \\n- А я']\n",
      "EPOCH 0 - epoch loss: 4.372243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:03<00:12,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: loss - 2.6672889232635497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:04<00:13,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу.  Вдруг видит: на дереве сидит медведь. \\n- А я']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:07<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: loss - 2.548545742034912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:08<00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу.  Вдруг видит — на дереве сидит мужик. \\n— Ты кто']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:11<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: loss - 2.467114973068237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:12<00:04,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу. Вдруг видит — на сосне сидит мужик.\\n— Что это ты']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:15<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: loss - 2.601138877868652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:16<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Шел медведь по лесу. Вдруг видит — на сосне сидит мужик и спрашивает:\\n— ']\n",
      "EPOCH 1 - epoch loss: 3.199173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    train_epoch(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoding strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трейдофф между связностью и разнообразием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Greedy decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На каждом шаге генерации выбираем самый вероятный токен.\n",
    "\n",
    "Получаем:\n",
    "- очень связный текст\n",
    "- невозможность получения разнообразных последовательностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/greedy_decoding.webp\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу. Вдруг видит — на сосне сидит мужик и спрашивает:\\n— ']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Шел медведь по лесу\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайно выбираем из первых К предложенных вариантов согласно предсказанным вероятностям токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/topk_sampling.webp\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу и вдруг видит:\\n- ААААААААААА!\\n-']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Шел медведь по лесу\", do_sample=True, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Softmax temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способ сделать распределение более равномерным.\n",
    "\n",
    "Таким образом, выбор в Top-k семплинге будет более разнообразный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/softmax_temperature.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чам больше температура, тем более равномерное распределение получается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу&hellip; И вдруг к одному мальчику. Ну все равно,']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Шел медведь по лесу\", do_sample=True, top_k=100, temperature=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проблемка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хочется сделать К динамическим: иногда вариантов очень много, а иногда - мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/topk_problem.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top-p sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К зависит от суммы вероятностей К предсказанных токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/top_p_sampling.webp\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу, \\nИ вдруг из леса навстречу ему\\nЛеопард выходит\\n']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Шел медведь по лесу\", do_sample=True, top_p=0.7, temperature=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прошлые методы выбирают следующий токен без учета контекста.\n",
    "\n",
    "Beam search - строит несколько вариантов генераций и выбирает самую вероятную *последовательность* токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/beam_search.webp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это требует больше вычислений, но результаты получаются намного лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу, а навстречу ему заяц. \\n- Здравствуй, медведь! ',\n",
       " 'Шел медведь по лесу, а навстречу ему заяц. \\n- Ты кто такой? ',\n",
       " 'Шел медведь по лесу, а навстречу ему заяц. \\n- Ты кто такой?\\n']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\n",
    "    \"Шел медведь по лесу\", \n",
    "    num_beams=4,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Шел медведь по лесу. \\nМедведь и говорит:\\n- У меня есть ружье. Я хочу, чтобы ты меня пострелял.\\nБандит обрадовался. \\n\\nИ говорит ему: \"Блядь, а я тебя поубивал, блядь\"\\nМохнатый отвечает:',\n",
       " 'Шел медведь по лесу. \\nМедведь и говорит:\\n- У меня есть ружье. Я хочу, чтобы ты меня пострелял.\\nБандит обрадовался. \\n\\nИ говорит ему: \"Блядь, а я тебя поубивал, блядь\"\\nМохнатый: ',\n",
       " 'Шел медведь по лесу. \\nМедведь и говорит:\\n- У меня есть ружье. Я хочу, чтобы ты меня пострелял.\\nБандит обрадовался. \\n\\nИ говорит ему: \"Блядь, а я тебя поубивал, блядь\"\\nМохнатый думает:']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\n",
    "    \"Шел медведь по лесу\", \n",
    "    max_length=64, \n",
    "    num_beams=4,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=3,\n",
    "    do_sample=True,\n",
    "    top_p=0.73,\n",
    "    temperature=2.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5: Transfer learning in all its glory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что если объединить BERT и GPT и решать оооочень много различных задач?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получится T5 - Encoder-Decoder transformer, предназначенный для решения text2text задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно представлять различные задачи в виде Text2text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/t5_multitask.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти как BERT, только сложнее: маскируем последовательности слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/t5_pretraining.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи:\n",
    "- Перевод - переводим с одного языка на другой.\n",
    "- Суммаризация - делаем краткий пересказ текста.\n",
    "- Question answering - отвечаем на вопрос по тексту.\n",
    "- Классификация текстов - относим текст к какой-то группе.\n",
    "- Генерация текстов - сочиняем (продолжаем) текст.\n",
    "- Регрессия по текстам - предсказываем число по тексту (анализ тональности, возраст, ...). \n",
    "- NLI (Natural language inference) - понимаем логическую связь предложений: продолжает, отрицает или не связано.\n",
    "- Сегментация текстов - находим отрезки текста, где что-то важное нам происходит (аспектный анализ тональности, ответ на вопрос, ...)\n",
    "\n",
    "*(Т5 училась не на все эти задачи, некоторые просто как пример.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/t5_tasks.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder vs Decoder-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Но ведь GPT умеет делать то же самое!\n",
    "- Да, что-то из этого может и BERT делать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/transformer-arch.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-only\n",
    "\n",
    "Всякие BERT, RoBERTa and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любые NLU-only задачи:\n",
    "- Text Classification\n",
    "- Sequence labelling\n",
    "- Sentiment analysis\n",
    "- NLI\n",
    "- QA\n",
    "- Search & Recommender systems (спойлер!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder-only\n",
    "\n",
    "Всякие GPT, XLNet and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любые чисто генеративные задачи:\n",
    "- Text completion\n",
    "- Text generation\n",
    "- Creative writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И задачи, где не требуется глубокое понимание:\n",
    "- диалоговые системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-Decoder\n",
    "\n",
    "Всякие Transformer, BART, T5 and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи на понимание + генерацию:\n",
    "- Machine translation\n",
    "- Summarization\n",
    "- QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реальность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем ChatGPT и погнали..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодим!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksiej/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/Users/aleksiej/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"cointegrated/rut5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У huggingface, кроме моделей, есть и датасеты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/huggingface_datasets.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "     num_rows: 100\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "     num_rows: 100\n",
       " })]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\", split=['train[0:100]', 'validation[0:100]'])\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Сегодня транспортный налог начисляется в зависимости от мощности автомобиля, причем цена для «сильных» машин выше, чем для малолитражек. Также ставку налога могут корректировать региональные власти: согласно Налоговому кодексу, базовый тариф, установленный правительством, может быть уменьшен в пять раз или увеличен до 10 раз. Сборы идут в региональные бюджеты, откуда растекаются на общие нужды. Транспортный налог — один из основных источников бюджетных доходов — предлагается направить исключительно на дорожные фонды. Так, автомобилисты будут понимать, за что они платят, а дорожники будут иметь гарантированный доход. Кроме налога дорожные фонды будут пополняться за счет бюджетных средств и проезда по платным дорогам. Более того, транспортный налог предлагается завуалировать в акцизы на бензин. Привычную и раздражающую систему ежегодной оплаты квитанции предлагается изменить, включив налог в стоимость топлива. Минэкономразвития говорит об удвоении акцизы, которая сегодня составляет 3,32 рубля за литр 92-го и 95-го бензина. Теперь платить будет не тот, кто купил машину мощнее, а тот, кто больше ездит. Владельцам многосильных автомобилей, которые сегодня отдают в год по 45–50 тысяч за машину, нововведение явно выгодно. Также выигрывают хозяева нескольких автомобилей, которые используются поочередно. Если в семье две-три машины, которые много стоят в гараже и не эксплуатируются, сейчас приходится платить за все. По новой схеме сбор будет значительно меньше. Но владельцы экономичных машин будут выкладывать гораздо больше при равном пробеге. Если цена бензина вырастет на 3,32 рубля, то владелец вазовской «девятки», потребляющей на 100 км в городе около 10 литров, заплатит в год 10162 рубля при среднем пробеге 30 тыс. км вместо 550 руб. по квитанции, а за Citroen C3 мощностью 73 л. с. и расходом 8,5 л на «сотню» придется в год выложить около 8,5 тысяч рублей. Сейчас – 511 руб. Хорошо укомплектованный Ford Focus cо 145-сильным мотором за 30 тыс. км. обойдется в 11155 «налоговых» рублей – на 6800 рублей дороже, чем при существующей ставке налогообложения, а вот налог на пожилой Mercedes-Benz S420 в кузове W140 при новой системе снизится почти вдвое. Сейчас владелец платит в год за 279 л. с. мотора около 41850 рублей. При среднем пробеге в 30 тыс. км в год и расходе топлива порядка 20 л на 100 км он истратит всего 6000 литров бензина и заплатит в казну вдвое меньше – 19920 рублей. С точки зрения власти решение отмены транспортного налога понятное и верное. В первую очередь, собираемость налога тут же возрастет до 100%, потому что новая система исключает возможность уклониться от уплаты. Кроме того, налоговая инспекция сэкономит бюджетные средства на доставке квитанций и судебных издержках при выколачивании средств с неплательщиков. Автоматически решается вопрос с бюрократической неразберихой после продажи машины или утилизации, когда налоговые органы присылают квитанцию на давно проданную машину. Но главное, что при новой схеме сборы значительно возрастут. Власти рассчитывают собирать до 62 млрд рублей в год. Экономисты уже предвидят тотальное повышение цен из-за роста стоимости перевозок. Ведь за бензин придется переплачивать и логистическим компаниям, которые включат дополнительные расходы в цену товара. Получается, что теперь за дороги будут платить не только автомобилисты, но и те, кто за рулем никогда не сидел. Но даже с учетом всех оговорок отмена транспортного налога — это важный и сильный политический шаг, который поможет снять напряжение в регионах. Дело в том, что скрытое налогообложение делает поборы незаметными и не травмирующими. Ведь власти и сейчас любят педалировать тем, что в стране самый низкий в Европе подоходный налог 13%. При этом они не афишируют другие отчисления в бюджет, которые снимаются с граждан с теми же акцизами и НДС. Есть также сомнения, что власти смогут обеспечить прозрачность расходования средств. Дорожные фонды в России уже существовали и были расформированы в 2000 году за коррупционность. Как предполагается распределять деньги между регионами и федеральным дорожным агентством и кто будет следить за потоками, в правительстве пока не решили.',\n",
       " 'summary': 'С 2011 года правительство отменяет самый раздражающий граждан налог – транспортный. Но поборы автомобилистов не прекратятся – налоги завуалируют в бензиновые акцизы и платные дороги, а цены на товары подскочат. Зато теперь собираемые деньги обещают пустить только на строительство и содержание дорог.',\n",
       " 'title': 'Налог в бак',\n",
       " 'date': '2010-06-01 10:35:49',\n",
       " 'url': 'https://www.gazeta.ru/auto/2010/05/31_a_3377717.shtml'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"], max_length=MAX_INPUT_LENGTH, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"title\"], \n",
    "            max_length=MAX_TARGET_LENGTH, \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0] = datasets[0].map(preprocess_data, batched=True)\n",
    "datasets[1] = datasets[1].map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['text', 'summary', 'title', 'date', 'url', 'input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 100\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'summary', 'title', 'date', 'url', 'input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 100\n",
       " })]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/seq2seq_arguments.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    \"t5_small_absum\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=lambda: T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small\"),\n",
    "    args=args,\n",
    "    train_dataset=datasets[0],\n",
    "    eval_dataset=datasets[1],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 27%|██▋       | 20/75 [00:29<01:18,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8417, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 27%|██▋       | 20/75 [00:36<01:18,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.26416015625, 'eval_runtime': 7.2146, 'eval_samples_per_second': 13.861, 'eval_steps_per_second': 3.465, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 40/75 [01:06<00:46,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2588, 'learning_rate': 4.666666666666667e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 53%|█████▎    | 40/75 [01:11<00:46,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1426470279693604, 'eval_runtime': 5.5186, 'eval_samples_per_second': 18.121, 'eval_steps_per_second': 4.53, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 60/75 [01:41<00:19,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1053, 'learning_rate': 2e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 80%|████████  | 60/75 [01:46<00:19,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.118772268295288, 'eval_runtime': 5.5099, 'eval_samples_per_second': 18.149, 'eval_steps_per_second': 4.537, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:08<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 128.5476, 'train_samples_per_second': 2.334, 'train_steps_per_second': 0.583, 'train_loss': 3.3105093892415365, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=3.3105093892415365, metrics={'train_runtime': 128.5476, 'train_samples_per_second': 2.334, 'train_steps_per_second': 0.583, 'train_loss': 3.3105093892415365, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем последний чекпоинт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"t5_small_absum/checkpoint-60\"\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_dir)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем суммаризовать какой-нибудь текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В 2020 году инфляция в России составит 3,5-4%, прогнозирует Центробанк. В первом квартале она ожидается так и вовсе ниже 3%. Впрочем, на ряд продовольственных товаров цены будут расти гораздо более высокими темпами. «Газета.Ru» разбиралась, какие продукты подорожают в новом году гораздо сильнее других. В 2019 году стоимость молока-сырья выросла на 9% и, как следствие, увеличилась цена на готовую продукцию: питьевое молоко за год подорожало на 7%, кефир, ряженка, творог — на 6 %, йогурт – на 8%, сметана на 7%, мороженое на 9%, полутвердые сыры на 10%, сливочное масло – на 11%, рассказала «Газете.Ru» заместитель председателя комитета МТПП по развитию предпринимательства в АПК, генеральный директор «Petrova 5 Consulting» Марина Петрова. По ее словам, в 2020 году стоит ожидать дальнейшего увеличения цен на молочные продукты. Темпы повышения, по ее словам, будут сопоставимы с ростом в 2019 году. «Производители плавно поднимают цены, потому что беспокоятся о возможном снижении объемов продаж в случае резкого подъема цен. Кроме сырья, на стоимость молочной продукции в наступающем году повлияет введение цифровой маркировки. «В случае введения маркировки в обозначенные сроки (середина 2020 года) произойдет рост себестоимости и часть небольших молочных заводов могут закрыться», — отметила Петрова. В первый год затраты переработчиков на маркировку вырастут на 20-25%. Они будут связаны с установкой необходимого оборудования, заказом новой упаковки и обязательным платежом за каждый QR-код — 50 копеек на единицу продукции. «Например, для завода с объемом выпуска 200 тонн в сутки ежегодные затраты на молочный акциз составят 50 млн рублей. При том, что сейчас такое предприятие в год платит налогов на 220 млн рублей», — пояснила эксперт. Директор Академии управления финансами и инвестициями Арсений Дадашев не исключает, что в 2020 году молочные продукты «способны подорожать рекордными темпами». По его словам, внедрение сертификации и обязательной маркировки приведут к увеличению издержек производителей более чем на 30 млрд рублей в год. «Во-вторых, сырое молоко по-прежнему остается дефицитом во многих регионах, тогда как спрос на натуральную продукцию растет после изменения регуляции и правил написания наименований товара на ценниках – население не так активно покупает «молокосодержащие продукты с заменителем молочного жира», — объяснил Дадашев. Напомним, 1 ноября 2019 года стартовал заключительный этап электронной ветеринарной сертификации. На молоко, как и на сыры, масло и творог будут оформляться сертификаты, позволяющие отследить движение товара. Эксперимент по маркировке некоторых видов молочной проукции продлится до конца февраля 2020 года. С 1 июня 2020 года маркировка станет обязательной. Ранее в Ассоциации компаний розничной торговли (АКОРТ) предсказали подорожание продуктов к концу года на 3,5%. Прогноз касается в первую очередь яиц, сахара и мяса птицы. По данным ассоциации, подорожание яиц и мяса птицы связано с сезонным фактором (осенью-зимой дорожает корм). Подорожание мяса птицы следует ожидать и в начале 2020 года. Впрочем, статистические данные не подтверждают этот прогноз. К тому же есть вероятность, что цены на мясо будут падать. Так, в 2019 году (с января по ноябрь) цены на яйца снизились на 10%, на куриное мясо – на 4,5%, на свинину – на 3,5%. В 2020 году запуск новых мощностей в мясной промышленности может сдержать рост цен и на говядину, как это произошло со свининой и куриным мясом, отметил руководитель партнерских программ инвестиционно-образовательной площадки «Линейка» Вячеслав Максименко. Оптовые цены на свинину в 2020 году продолжат снижаться, к среднему уровню цен этого года снижение может составить 3-5%, прогнозировал руководитель Национальной мясной ассоциации России Сергей Юшин. С 1 января повышаются минимальные розничные цены на водку, коньяк, бренди и ликероводочные изделия. Минимальная розничная цена на водку увеличится на 7%, до 230 рублей за бутылку объемом 0,5 литра с текущих 215 рублей. «Каждый год, как и все продукты питания, алкоголь дорожает. На продукты питания влияет в основном инфляция, рост накладных расходов у производителей и так далее. Известно, что примерно с 2000 по 2019 год цены на продукты выросли в четыре раза. Аналогично растет и цена на алкоголь, но здесь дополнительно к инфляционным моментам добавляются еще такие, как рост ставки акциза и стоимость комплектации», — говорит директор центра «Цифрра» Вадим Дробиз. По его словам, в 2020 году возрастает и ставка акциза, и цена спирта, а также накладные расходы производителей. «Минимальная цена на водку поднимается с 215 до 230 рублей, а реально, наверно, 240 рублей», — отметил Дробиз. Минимальная цена коньяка вырастет более чем на 11%, до 433 рублей за бутылку 0,5 литра с текущих 388 рублей. Минимальная цена бренди — 315 рублей. «В целом крепкий алкоголь вырастет в цене на 5-7%», — подвел итог Дробиз. Что касается вина, эксперт также прогнозирует рост цен как минимум на 5%. С 1 января 2020 года действуют акцизы на электронные сигареты, вейпы и жидкости для них. Так что теперь, использовать устройства, вроде Iqos и qlo станет гораздо дороже. Акцизы на сигареты и папиросы вырастут примерно на 4%. Если сейчас акциз на сигареты составляет не менее 2 560 рублей за 1000 сигарет, то уже с начала года повысится до 2670 рублей. В 2019 году хороший урожай привел к тому, что с начала года по ноябрь плодоовощная продукция в целом подешевела на 5,7%, а прирост цен в целом на продукты питания за этот период составил лишь 1,9%. «Цифры могут выглядеть неправдоподобно на фоне, к примеру, роста цен на гречневую крупу (на 32% к середине декабря), рис (7,3%) или рыбу (10,3%), но это объясняется различным «весом» каждого товара в общей потребительской корзине, которая носит усредненный характер», — указывает Максименко. Кстати, эксперты (АКОРТ) ожидают дальнейшего подорожания гречневой крупы из-за сокращения посевов гречихи. Позитивную динамику ценам на продукты помимо фруктов и овощей в прошлом году обеспечило и снижение цен на сахар (почти на 30% с января по ноябрь), яйца (10%), куриное мясо (4,5%) и свинину (3,5%). «В грядущем году, если погода не будет столь милостива, фрукты и овощи могут подорожать. Резкий рост цен на гречневую крупу приведет к переориентации сельхозпроизводителей на ее выпуск, что приведет к корректировке цен. Снижение цен на яйца и сахар остановится из-за сокращения их производства», — отметил Максименко. Что касается цены на хлеб, она не должна вырасти существенно, сказал «Газете.Ru» Арсений Дадашев. Теплая погода в России поддерживает рост озимых и не позволяет внутренним ценам расти вслед за экспортными. В 2019 году из-за плохого урожая злаковых культур, цены на хлебобулочные изделия увеличились почти на 8%. «Запасы в стране остаются внушительные, так что предприятия смогут и нарастить экспорт в случае необходимости и обеспечить спрос со стороны отечественных заводов. Ожидаем подорожание в пределах инфляции», — подвел итог эксперт.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_summarize = datasets[1][0][\"text\"]\n",
    "text_to_summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text_to_summarize, max_length=MAX_INPUT_LENGTH, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**inputs, min_length=10, max_length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   259,  6825,   310,  8745,  2093,   315,   972,  5546,   259,\n",
       "          4466,   259, 16554,     1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Цена на молоко в 2020 году будет расти'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/third/hny_meme.jpeg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/second/thanks_attention.png\" width=\"1200\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
