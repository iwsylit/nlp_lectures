{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/nlp_experts.jpg\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ЧБДТ: Что Было До Трансформеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План занятий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ЧБДТ: Что Было До Трансформеров\n",
    "   1. При чём тут нейро-лингвистическое программирование?\n",
    "   2. Почему вектора?\n",
    "   3. Счётные методы: CountVectorizer, TF-IDF, добавляем контекст \n",
    "   4. Дистрибутивная семантика: Word2vec, FastText\n",
    "   5. Рекуррентные нейронные сети: LSTM, GRU\n",
    "### 2. Трансформеры: база\n",
    "   1. Мотивация\n",
    "   2. Attention из all you need?: виды attention, интуиция, реализация\n",
    "   3. Архитектура Transformer: эмбеддинги, энкодер, декодер\n",
    "### 3. Трансформеры: на волне хайпа\n",
    "   1. BERT\n",
    "   2. GPT\n",
    "   3. T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краткое введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Где используется NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/nlp_examples.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чат-боты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/ChatGPT.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переводчики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/translator.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приложения для изучения языков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/duolingo.webp\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/reverso.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Суммаризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/Summarizer.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Есть проблемы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная проблема всея ML - классификация. Это верно и для NLP.\n",
    "\n",
    "Например:\n",
    "1. Спам или что-то осмысленное?\n",
    "2. Позитивное или негативное?\n",
    "3. К какой теме относится?\n",
    "4. Что от нас хочет пользователь?\n",
    "5. Токсичность, оскорбления или ок?\n",
    "\n",
    "Нужно как-то заставить компьютер понимать язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Почему вектора?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/vectors.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плюсы\n",
    "1. Понятно для компьютера\n",
    "2. Хорошо умеем с ними работать (математика + машинное обучение)\n",
    "3. Можем заложить знания о языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минусы\n",
    "1. Большое упрощение\n",
    "2. Неинтерпретируемо (иногда)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поехали..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install openpyxl pandas torch transformers pymorphy3 pymorphy3-dicts-ru navec\n",
    "%pip install scikit-learn nltk matplotlib seaborn gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget -nc https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n",
    "!mv navec_hudlit_v1_12B_500K_300d_100q.tar data/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import nltk; nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Счётные методы (BoW) + предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основная идея\n",
    "Считаем все слова в тексте; представляем текст как вектор (1 х V), где V - размер словаря (количество уникальных слов во всех текстах выборки). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например: Моя мама мыла раму. Раму мыла мама, мама.\n",
    "\n",
    "||моя|мама|мыла|раму|\n",
    "|-|-|-|-|-|\n",
    "|1.|1|1|1|1|\n",
    "|2.|0|2|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В scikit-learn для этого существует `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_dataset = [\"моя мама мыла раму\", \"раму мыла мама, мама\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Токенизатор** - это программа или алгоритм, который разбивает текст на отдельные единицы, называемые токенами. \\\n",
    "Токены могут быть словами, символами, знаками препинания или другими элементами, которые важны для нашей задачи.\n",
    "\n",
    "Напишем свой собственный токенизатор!\n",
    "\n",
    "*(а можно было взять уже готовый из [razdel](https://github.com/natasha/razdel), spacy, nltk, ...)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/tokenizers.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_regex = re.compile(r\"\\w+\")\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    return re.findall(tokenization_regex, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['моя', 'мама', 'мыла', 'раму'], ['раму', 'мыла', 'мама', 'мама']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_micro_dataset = list(map(tokenize, micro_dataset))\n",
    "tokenized_micro_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstrip_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(?u)\\\\b\\\\w\\\\w+\\\\b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.int64'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Convert a collection of text documents to a matrix of token counts.\n",
      "\n",
      "This implementation produces a sparse representation of the counts using\n",
      "scipy.sparse.csr_matrix.\n",
      "\n",
      "If you do not provide an a-priori dictionary and you do not use an analyzer\n",
      "that does some kind of feature selection then the number of features will\n",
      "be equal to the vocabulary size found by analyzing the data.\n",
      "\n",
      "For an efficiency comparision of the different feature extractors, see\n",
      ":ref:`sphx_glr_auto_examples_text_plot_hashing_vs_dict_vectorizer.py`.\n",
      "\n",
      "Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : {'filename', 'file', 'content'}, default='content'\n",
      "    - If `'filename'`, the sequence passed as an argument to fit is\n",
      "      expected to be a list of filenames that need reading to fetch\n",
      "      the raw content to analyze.\n",
      "\n",
      "    - If `'file'`, the sequence items must have a 'read' method (file-like\n",
      "      object) that is called to fetch the bytes in memory.\n",
      "\n",
      "    - If `'content'`, the input is expected to be a sequence of items that\n",
      "      can be of type string or byte.\n",
      "\n",
      "encoding : str, default='utf-8'\n",
      "    If bytes or files are given to analyze, this encoding is used to\n",
      "    decode.\n",
      "\n",
      "decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n",
      "    Instruction on what to do if a byte sequence is given to analyze that\n",
      "    contains characters not of the given `encoding`. By default, it is\n",
      "    'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      "    values are 'ignore' and 'replace'.\n",
      "\n",
      "strip_accents : {'ascii', 'unicode'} or callable, default=None\n",
      "    Remove accents and perform other character normalization\n",
      "    during the preprocessing step.\n",
      "    'ascii' is a fast method that only works on characters that have\n",
      "    a direct ASCII mapping.\n",
      "    'unicode' is a slightly slower method that works on any characters.\n",
      "    None (default) means no character normalization is performed.\n",
      "\n",
      "    Both 'ascii' and 'unicode' use NFKD normalization from\n",
      "    :func:`unicodedata.normalize`.\n",
      "\n",
      "lowercase : bool, default=True\n",
      "    Convert all characters to lowercase before tokenizing.\n",
      "\n",
      "preprocessor : callable, default=None\n",
      "    Override the preprocessing (strip_accents and lowercase) stage while\n",
      "    preserving the tokenizing and n-grams generation steps.\n",
      "    Only applies if ``analyzer`` is not callable.\n",
      "\n",
      "tokenizer : callable, default=None\n",
      "    Override the string tokenization step while preserving the\n",
      "    preprocessing and n-grams generation steps.\n",
      "    Only applies if ``analyzer == 'word'``.\n",
      "\n",
      "stop_words : {'english'}, list, default=None\n",
      "    If 'english', a built-in stop word list for English is used.\n",
      "    There are several known issues with 'english' and you should\n",
      "    consider an alternative (see :ref:`stop_words`).\n",
      "\n",
      "    If a list, that list is assumed to contain stop words, all of which\n",
      "    will be removed from the resulting tokens.\n",
      "    Only applies if ``analyzer == 'word'``.\n",
      "\n",
      "    If None, no stop words will be used. In this case, setting `max_df`\n",
      "    to a higher value, such as in the range (0.7, 1.0), can automatically detect\n",
      "    and filter stop words based on intra corpus document frequency of terms.\n",
      "\n",
      "token_pattern : str or None, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n",
      "    Regular expression denoting what constitutes a \"token\", only used\n",
      "    if ``analyzer == 'word'``. The default regexp select tokens of 2\n",
      "    or more alphanumeric characters (punctuation is completely ignored\n",
      "    and always treated as a token separator).\n",
      "\n",
      "    If there is a capturing group in token_pattern then the\n",
      "    captured group content, not the entire match, becomes the token.\n",
      "    At most one capturing group is permitted.\n",
      "\n",
      "ngram_range : tuple (min_n, max_n), default=(1, 1)\n",
      "    The lower and upper boundary of the range of n-values for different\n",
      "    word n-grams or char n-grams to be extracted. All values of n such\n",
      "    such that min_n <= n <= max_n will be used. For example an\n",
      "    ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means\n",
      "    unigrams and bigrams, and ``(2, 2)`` means only bigrams.\n",
      "    Only applies if ``analyzer`` is not callable.\n",
      "\n",
      "analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n",
      "    Whether the feature should be made of word n-gram or character\n",
      "    n-grams.\n",
      "    Option 'char_wb' creates character n-grams only from text inside\n",
      "    word boundaries; n-grams at the edges of words are padded with space.\n",
      "\n",
      "    If a callable is passed it is used to extract the sequence of features\n",
      "    out of the raw, unprocessed input.\n",
      "\n",
      "    .. versionchanged:: 0.21\n",
      "\n",
      "    Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n",
      "    first read from the file and then passed to the given callable\n",
      "    analyzer.\n",
      "\n",
      "max_df : float in range [0.0, 1.0] or int, default=1.0\n",
      "    When building the vocabulary ignore terms that have a document\n",
      "    frequency strictly higher than the given threshold (corpus-specific\n",
      "    stop words).\n",
      "    If float, the parameter represents a proportion of documents, integer\n",
      "    absolute counts.\n",
      "    This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "min_df : float in range [0.0, 1.0] or int, default=1\n",
      "    When building the vocabulary ignore terms that have a document\n",
      "    frequency strictly lower than the given threshold. This value is also\n",
      "    called cut-off in the literature.\n",
      "    If float, the parameter represents a proportion of documents, integer\n",
      "    absolute counts.\n",
      "    This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "max_features : int, default=None\n",
      "    If not None, build a vocabulary that only consider the top\n",
      "    `max_features` ordered by term frequency across the corpus.\n",
      "    Otherwise, all features are used.\n",
      "\n",
      "    This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "vocabulary : Mapping or iterable, default=None\n",
      "    Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      "    indices in the feature matrix, or an iterable over terms. If not\n",
      "    given, a vocabulary is determined from the input documents. Indices\n",
      "    in the mapping should not be repeated and should not have any gap\n",
      "    between 0 and the largest index.\n",
      "\n",
      "binary : bool, default=False\n",
      "    If True, all non zero counts are set to 1. This is useful for discrete\n",
      "    probabilistic models that model binary events rather than integer\n",
      "    counts.\n",
      "\n",
      "dtype : dtype, default=np.int64\n",
      "    Type of the matrix returned by fit_transform() or transform().\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "vocabulary_ : dict\n",
      "    A mapping of terms to feature indices.\n",
      "\n",
      "fixed_vocabulary_ : bool\n",
      "    True if a fixed vocabulary of term to indices mapping\n",
      "    is provided by the user.\n",
      "\n",
      "stop_words_ : set\n",
      "    Terms that were ignored because they either:\n",
      "\n",
      "      - occurred in too many documents (`max_df`)\n",
      "      - occurred in too few documents (`min_df`)\n",
      "      - were cut off by feature selection (`max_features`).\n",
      "\n",
      "    This is only available if no vocabulary was given.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "HashingVectorizer : Convert a collection of text documents to a\n",
      "    matrix of token counts.\n",
      "\n",
      "TfidfVectorizer : Convert a collection of raw documents to a matrix\n",
      "    of TF-IDF features.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The ``stop_words_`` attribute can get large and increase the model size\n",
      "when pickling. This attribute is provided only for introspection and can\n",
      "be safely removed using delattr or set to None before pickling.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
      ">>> corpus = [\n",
      "...     'This is the first document.',\n",
      "...     'This document is the second document.',\n",
      "...     'And this is the third one.',\n",
      "...     'Is this the first document?',\n",
      "... ]\n",
      ">>> vectorizer = CountVectorizer()\n",
      ">>> X = vectorizer.fit_transform(corpus)\n",
      ">>> vectorizer.get_feature_names_out()\n",
      "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
      "       'this'], ...)\n",
      ">>> print(X.toarray())\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      ">>> vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
      ">>> X2 = vectorizer2.fit_transform(corpus)\n",
      ">>> vectorizer2.get_feature_names_out()\n",
      "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
      "       'second document', 'the first', 'the second', 'the third', 'third one',\n",
      "       'this document', 'this is', 'this the'], ...)\n",
      " >>> print(X2.toarray())\n",
      " [[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/feature_extraction/text.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     TfidfVectorizer"
     ]
    }
   ],
   "source": [
    "?CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>мама</th>\n",
       "      <th>моя</th>\n",
       "      <th>мыла</th>\n",
       "      <th>раму</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   мама  моя  мыла  раму\n",
       "0     1    1     1     1\n",
       "1     2    0     1     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "vectors = vectorizer.fit_transform(tokenized_micro_dataset)\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая проблема будет для предложения \"Мы увидели зеленый стол, подошли к зеленому столу, пододвинули другие зелёные столы.\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизация\n",
    "**Лемматизация** - приведение слов в нормальную форму. \\\n",
    "Нормальная форма обычно является именительным падежом единственного числа для существительных, инфинитивом для глаголов, мужским родом для прилагательных и т.д. Лемматизация учитывает морфологические и синтаксические особенности языка и пытается сохранить смысл слова. \n",
    "\n",
    "Есть ещё **стемминг** - удаление суффиксов/окончаний, чтобы получить его основу или корень. \\\n",
    "Основа или корень не обязательно является нормальной формой или даже существующим словом, а просто общим элементом для группы слов.\n",
    "\n",
    "Лемматизированный текст: мы увидеть зеленый стол, подойти к зеленый стол, пододвинуть другой зеленый стол. \\\n",
    "Стеммированный текст: мы увид зелен стол, подошл к зелен стол, пододвин друг зелен стол."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для русского обычно используют лемматизацию. В питоне с помощью библиотек: pymorphy2/3, natasha, rmmnorph, spacy, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(word: str) -> str:\n",
    "    return morph.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['мой', 'мама', 'мыло', 'рама'], ['рама', 'мыло', 'мама', 'мама']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: list(map(lemmatize, x)), tokenized_micro_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая будет проблема, если тексты будут очень разной длины?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема - частоты слов будут несопоставимы. \\\n",
    "Решение - используем бинарный векторайзер: ставим 1, если слово встретилось хотя бы один раз; ставим 0, если слова не было в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>мама</th>\n",
       "      <th>моя</th>\n",
       "      <th>мыла</th>\n",
       "      <th>раму</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   мама  моя  мыла  раму\n",
       "0     1    1     1     1\n",
       "1     1    0     1     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: x, lowercase=False, binary=True)\n",
    "vectors = vectorizer.fit_transform(tokenized_micro_dataset)\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие ещё проблемы будут?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсказка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Закон Ципфа\n",
    "\n",
    "Частота слова в языке обратно пропорциональна порядковому номеру этого слова.\n",
    "\n",
    "<img src=\"attachements/first/zipf.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема - самые частотные слова будут встречаться чаще всего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стоп-слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cтоп-слова - слова, которые бесполезны для решения задачи, мусорные слова. Часто - достаточно частотные в языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'что', 'он', 'на', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as stopwords_nltk\n",
    "\n",
    "stopwords = stopwords_nltk.words('russian')\n",
    "stopwords = [w for w in stopwords if w not in ['не', 'нет', 'я']]\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_meaningful(word: str) -> bool:\n",
    "    return word not in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Финальный пайплайн предобработки текста:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Привести к нижнему регистру\n",
    "2. Токенизировать\n",
    "3. Лемматизировать\n",
    "4. Убрать стоп-слова\n",
    "\n",
    "В зависимости от вашей задачи и используемых методов - пайплайн может меняться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> list[str]:\n",
    "    text = text.lower()\n",
    "    tokens = tokenize(text)\n",
    "    lemmas = map(lemmatize, tokens)\n",
    "    lemmas_meaningful = filter(is_meaningful, lemmas)\n",
    "\n",
    "    return list(lemmas_meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['зелёный', 'трава', 'зеленить', 'зелёный', 'трава']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(\"Зелёная трава зеленила зелёную траву!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея: перевзвесить слова таким образом, чтобы частотным словам (которые встречаются в большом количестве документов)\n",
    "придать вес поменьше, а редким (специфическим для определенных текстов) словам - побольше.\n",
    "\n",
    "<img src=\"attachements/first/tfidf.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему в формуле логарифм?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>мама</th>\n",
       "      <th>моя</th>\n",
       "      <th>мыла</th>\n",
       "      <th>раму</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.630099</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.448321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       мама       моя      мыла      раму\n",
       "0  0.448321  0.630099  0.448321  0.448321\n",
       "1  0.816497  0.000000  0.408248  0.408248"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "vectors = vectorizer.fit_transform(tokenized_micro_dataset)\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['моя мама мыла раму', 'раму мыла мама, мама']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно TF-IDF оказывается лучше других счётных методов, но иногда и другие стреляют."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли ещё проблемы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсказка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как будут представлены предложения \"я тебя не люблю\" и \"я люблю не тебя\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем контекстуальность через би-, три- и тд-граммы!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/ngrams.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>мама</th>\n",
       "      <th>мама мама</th>\n",
       "      <th>мама мыла</th>\n",
       "      <th>мама мыла раму</th>\n",
       "      <th>моя</th>\n",
       "      <th>моя мама</th>\n",
       "      <th>моя мама мыла</th>\n",
       "      <th>мыла</th>\n",
       "      <th>мыла мама</th>\n",
       "      <th>мыла мама мама</th>\n",
       "      <th>мыла раму</th>\n",
       "      <th>раму</th>\n",
       "      <th>раму мыла</th>\n",
       "      <th>раму мыла мама</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   мама  мама мама  мама мыла  мама мыла раму  моя  моя мама  моя мама мыла  \\\n",
       "0     1          0          1               1    1         1              1   \n",
       "1     2          1          0               0    0         0              0   \n",
       "\n",
       "   мыла  мыла мама  мыла мама мама  мыла раму  раму  раму мыла  раму мыла мама  \n",
       "0     1          0               0          1     1          0               0  \n",
       "1     1          1               1          0     1          1               1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: x, lowercase=False, ngram_range=(1, 3))\n",
    "vectors = vectorizer.fit_transform(tokenized_micro_dataset)\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как будем решать проблему с огромной размерностью получившейся матрицы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обрезать совсем редкие н-граммы или токены\n",
    "2. Снижать размерность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dataset.txt\")as file:\n",
    "    data = file.read().split(\"\\n\")[:-1]\n",
    "    data = list(map(lambda x: x.split(\" \", maxsplit=1), data))\n",
    "    data = pd.DataFrame(data, columns=[\"target\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__INSULT</td>\n",
       "      <td>скотина! что сказать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>я сегодня проезжала по рабочей и между домами ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>очередной лохотрон. зачем придумывать очередно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>ретро дежавю ... сложно понять чужое сердце , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__NORMAL</td>\n",
       "      <td>а когда мы статус агрогородка получили?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                                               text\n",
       "0  __label__INSULT                               скотина! что сказать\n",
       "1  __label__NORMAL  я сегодня проезжала по рабочей и между домами ...\n",
       "2  __label__NORMAL  очередной лохотрон. зачем придумывать очередно...\n",
       "3  __label__NORMAL  ретро дежавю ... сложно понять чужое сердце , ...\n",
       "4  __label__NORMAL            а когда мы статус агрогородка получили?"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "__label__NORMAL                                       203685\n",
       "__label__INSULT                                        28567\n",
       "__label__INSULT,__label__THREAT                         6317\n",
       "__label__THREAT                                         5460\n",
       "__label__OBSCENITY                                      2245\n",
       "__label__INSULT,__label__OBSCENITY                      1766\n",
       "__label__INSULT,__label__OBSCENITY,__label__THREAT       176\n",
       "__label__OBSCENITY,__label__THREAT                        74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"target\"] \\\n",
    "    .apply(lambda x: \"__label__OBSCENITY\" if \"OBSCENITY\" in x else x) \\\n",
    "    .apply(lambda x: \"__label__THREAT\" if \"THREAT\" in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "__label__NORMAL       203685\n",
       "__label__INSULT        28567\n",
       "__label__THREAT        11777\n",
       "__label__OBSCENITY      4261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).groupby(\"target\").head(6666).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "__label__INSULT       6666\n",
       "__label__NORMAL       6666\n",
       "__label__THREAT       6666\n",
       "__label__OBSCENITY    4261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"target\"].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>это твоя мама толстая все сжирает,а у путьки н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>правда на 100% . прежде чем что то требовать н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>все правильно не уступай трамваю, и поездам то...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>таких людей убивать нужно, бедный ребёнок, сер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>опять театр опять развлекуха!! опять клоуны, а...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  это твоя мама толстая все сжирает,а у путьки н...\n",
       "1       1  правда на 100% . прежде чем что то требовать н...\n",
       "2       0  все правильно не уступай трамваю, и поездам то...\n",
       "3       2  таких людей убивать нужно, бедный ребёнок, сер...\n",
       "4       1  опять театр опять развлекуха!! опять клоуны, а..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24259 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24259/24259 [00:19<00:00, 1246.75it/s]\n"
     ]
    }
   ],
   "source": [
    "data[\"processed_text\"] = data[\"text\"].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>это твоя мама толстая все сжирает,а у путьки н...</td>\n",
       "      <td>[это, твой, мама, толстой, всё, сжирать, путьк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>правда на 100% . прежде чем что то требовать н...</td>\n",
       "      <td>[правда, 100, прежде, требовать, дать, вложиться]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>все правильно не уступай трамваю, и поездам то...</td>\n",
       "      <td>[всё, правильно, не, уступать, трамвай, поезд,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>таких людей убивать нужно, бедный ребёнок, сер...</td>\n",
       "      <td>[человек, убивать, нужно, бедный, ребёнок, сер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>опять театр опять развлекуха!! опять клоуны, а...</td>\n",
       "      <td>[театр, развлекуха, клоун, рабочий, класс, сел...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  это твоя мама толстая все сжирает,а у путьки н...   \n",
       "1       1  правда на 100% . прежде чем что то требовать н...   \n",
       "2       0  все правильно не уступай трамваю, и поездам то...   \n",
       "3       2  таких людей убивать нужно, бедный ребёнок, сер...   \n",
       "4       1  опять театр опять развлекуха!! опять клоуны, а...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  [это, твой, мама, толстой, всё, сжирать, путьк...  \n",
       "1  [правда, 100, прежде, требовать, дать, вложиться]  \n",
       "2  [всё, правильно, не, уступать, трамвай, поезд,...  \n",
       "3  [человек, убивать, нужно, бедный, ребёнок, сер...  \n",
       "4  [театр, развлекуха, клоун, рабочий, класс, сел...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24259.000000\n",
       "mean         8.337483\n",
       "std          9.629260\n",
       "min          0.000000\n",
       "50%          5.000000\n",
       "99%         51.000000\n",
       "max        155.000000\n",
       "Name: processed_text, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"processed_text\"].str.len().describe(percentiles=[0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"processed_text\"].apply(len) >= 3].reset_index(drop=True)\n",
    "data[\"processed_text\"] = data[\"processed_text\"].apply(lambda x: x[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    5714\n",
       "2    5502\n",
       "1    5385\n",
       "3    3580\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.15, stratify=data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_data[\"processed_text\"].values, test_data[\"processed_text\"] \n",
    "y_train, y_test = train_data[\"target\"].values, test_data[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1, 1), \n",
    "        max_features=10000,  # Взяли с потолка!\n",
    "        tokenizer=lambda x: x, \n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('svm',  LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(lowercase=False, max_features=10000,\n",
       "                                 tokenizer=&lt;function &lt;lambda&gt; at 0x296c38a40&gt;)),\n",
       "                (&#x27;svm&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(lowercase=False, max_features=10000,\n",
       "                                 tokenizer=&lt;function &lt;lambda&gt; at 0x296c38a40&gt;)),\n",
       "                (&#x27;svm&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(lowercase=False, max_features=10000,\n",
       "                tokenizer=&lt;function &lt;lambda&gt; at 0x296c38a40&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(lowercase=False, max_features=10000,\n",
       "                                 tokenizer=<function <lambda> at 0x296c38a40>)),\n",
       "                ('svm', LinearSVC())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(y_true, y_pred, average='macro'):\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "\n",
    "    print(f'{average.capitalize()} Precision = {precision:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}')\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision = 0.9706, Recall = 0.9702, F1 = 0.9704\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(y_train, pred_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision = 0.8261, Recall = 0.8224, F1 = 0.8238\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(y_test, pred_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дистрибутивная семантика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "Получить \"экспрессивные\" вектора для слов.\n",
    "### Идея\n",
    "Значение слова определяется его контекстом. Значит, нужно заложить информацию о возможных контекстах в вектор слова.\n",
    "\n",
    "<img src=\"attachements/first/distributional_semantics.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронная сеть, параметры которой - вектора слов. Вектора обновляются итеративно, как при обучении любой нейронки.\n",
    "\n",
    " - Учим модель предсказывать слова контекста по центральному слову (было слово в контексте или нет) - **Skip-gram**\n",
    " - Либо наоборот! Предсказывать слово по контексту (было слово в центре или нет) - **CBOW**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн обучения:\n",
    "* Берём огромный корпус текстов (без разметки - self-supervised learning!)\n",
    "* Шагаем по текстам, слово за словом. На каждом шаге смотрим на центральное слово и контекст (заданного размера)\n",
    "* Смотря на центральное слово, считаем вероятности того, что слово из контекста находится радом с центральным словом - **Skip-gram**\n",
    "  * Либо наоборот! Смотрим на слова контекста, считаем вероятности того, что центральное слово находится рядом с контекстами - **CBOW**\n",
    "* Изменяем вектора, чтобы увеличить эту вероятность (бэк-проп, градиентный спуск, все дела)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/w2v_training.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лосс\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW vs Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/cbow_skipgram.webp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос\n",
    "Какие преимущества у каждого из методов в каких ситуациях?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плюсы CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Лучше для частотных слов (почему?)\n",
    "- Лучше учит синтаксические связи (кот и коты ближе друг к другу)\n",
    "- Учится быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плюсы Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Меньше переобучается на частотные слова\n",
    "- Лучше выражает редкие слова\n",
    "- Требует меньше данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будем делать со словами, которых у нас нет в словаре?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем специальный токен \\<unk\\> и будем учить как обычно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интуиция и прикольные свойства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/w2v_properties.jpg\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "\n",
    "navec = Navec.load('data/navec_hudlit_v1_12B_500K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.14312136e-01,  3.70287180e-01,  1.36796311e-01, -1.86535835e-01,\n",
       "       -4.91572991e-02, -1.88751370e-02, -1.32190725e-02,  3.57939489e-02,\n",
       "       -3.97918969e-02,  1.94128811e-01, -8.25866908e-02,  2.47690390e-04,\n",
       "        2.88263001e-02,  2.01173663e-01, -1.54272586e-01, -1.13935187e-01,\n",
       "       -4.74858470e-02, -7.92295299e-03,  6.50205165e-02, -3.78477909e-02,\n",
       "        6.24999329e-02,  2.49566153e-01,  1.03294946e-01, -2.11493388e-01,\n",
       "       -1.73085947e-02, -2.82477215e-02, -6.87575415e-02, -9.21097770e-02,\n",
       "        8.71437322e-03, -1.69095173e-01, -5.73454238e-02,  4.21022065e-02,\n",
       "       -5.24346411e-01, -1.58332035e-01,  5.83604947e-02, -6.78519439e-03,\n",
       "       -6.93208054e-02, -5.74708311e-03, -1.20353170e-01, -4.40001450e-02,\n",
       "        4.75032702e-02, -2.33378902e-01, -1.33015737e-01,  1.27385199e-01,\n",
       "       -7.16302916e-02,  1.28748834e-01,  1.13330811e-01,  1.26265138e-02,\n",
       "        5.89972734e-02,  2.43283421e-01, -8.16499963e-02,  2.72306442e-01,\n",
       "        1.67372063e-01, -1.33618921e-01,  1.89889565e-01, -9.01413932e-02,\n",
       "        1.14899948e-01, -5.96789792e-02,  6.26452938e-02, -1.41223237e-01,\n",
       "       -2.08740175e-01,  3.32493484e-01,  2.14649692e-01, -3.34672779e-02,\n",
       "        5.25368713e-02, -1.45456240e-01,  1.46174431e-01,  1.52270079e-01,\n",
       "       -9.52247530e-03,  2.50804238e-02,  2.03919202e-01, -4.77523766e-02,\n",
       "        6.55542389e-02, -4.80662771e-02, -2.27324516e-02,  1.13046184e-01,\n",
       "       -1.54620215e-01,  4.85879853e-02, -9.92703661e-02,  1.33642517e-02,\n",
       "        3.87403667e-01,  1.51388884e-01,  4.65942472e-02,  3.72258306e-01,\n",
       "        8.34996030e-02, -1.95314333e-01,  4.20905292e-01, -1.83610618e-02,\n",
       "        8.96160752e-02,  9.06159878e-02, -1.41039923e-01,  1.38926119e-01,\n",
       "        1.75671160e-01, -4.77052480e-02,  6.52849749e-02, -1.81734160e-01,\n",
       "        1.34497583e-01,  4.52925228e-02,  1.77893162e-01,  8.24629366e-02,\n",
       "       -2.26429254e-02, -7.81486835e-03,  1.04925431e-01,  1.10557005e-01,\n",
       "       -2.29530305e-01,  9.88782197e-02,  3.10462683e-01, -8.70207101e-02,\n",
       "       -1.03182040e-01,  2.13678405e-01, -2.50720121e-02,  1.29431337e-01,\n",
       "        1.54199198e-01, -2.19486684e-01,  3.71575169e-02, -7.83453137e-02,\n",
       "        7.56102279e-02, -1.48542151e-01, -1.30579412e-01, -1.72655612e-01,\n",
       "       -2.32030213e-01,  1.96986243e-01, -1.19844198e-01, -1.61239907e-01,\n",
       "       -1.23323025e-02,  1.08766764e-01,  1.77958250e-01,  1.16608568e-01,\n",
       "        5.23438416e-02,  8.04402903e-02,  1.20596744e-01,  2.01546252e-01,\n",
       "       -2.42847838e-02, -5.51940240e-02,  3.43268484e-01, -1.74818859e-01,\n",
       "       -1.89623818e-01,  1.73824951e-02, -5.79115637e-02,  7.34661222e-02,\n",
       "       -1.77343175e-01,  9.75643843e-02,  3.94618399e-02,  5.85069545e-02,\n",
       "        8.76323134e-02,  1.29697844e-01, -9.66188908e-02, -7.55561888e-02,\n",
       "        4.56631891e-02, -7.39202276e-02, -1.87734172e-01, -2.26111129e-01,\n",
       "       -8.17668959e-02, -1.41328156e-01, -4.58951257e-02, -6.45612031e-02,\n",
       "       -1.69128492e-01,  1.30283371e-01, -8.07456896e-02, -1.02156378e-01,\n",
       "        2.47294649e-01, -5.10989875e-02,  3.03961843e-01, -4.96661589e-02,\n",
       "        5.26514724e-02, -4.51278463e-02, -7.08152354e-02, -9.64756496e-03,\n",
       "        1.41175479e-01, -4.36366862e-03, -1.09772854e-01, -1.34531349e-01,\n",
       "       -5.43047376e-02, -2.91877270e-01, -4.83813137e-02, -1.34292915e-01,\n",
       "        9.67178047e-02,  1.76384658e-01, -3.54634225e-02,  1.23027198e-01,\n",
       "        1.27308547e-01,  7.43818954e-02, -7.57130086e-02, -1.14989795e-01,\n",
       "       -4.12835032e-02, -9.14284028e-03,  2.74244636e-01,  2.01127961e-01,\n",
       "        7.64898211e-02, -3.65237296e-01,  1.13204330e-01,  8.54145437e-02,\n",
       "       -1.00724556e-01,  1.60300419e-01,  1.62792996e-01, -2.01577187e-01,\n",
       "       -2.94318765e-01, -9.03087929e-02, -1.12690747e-01, -2.36844774e-02,\n",
       "       -4.28256869e-01, -1.17189415e-01,  2.29112849e-01, -8.28808025e-02,\n",
       "       -4.25634146e-01, -3.64379436e-01, -7.13650361e-02, -1.90144539e-01,\n",
       "        6.87066326e-03,  1.48484232e-02,  1.77946210e-01,  1.81121826e-01,\n",
       "       -2.69022007e-02, -9.54891741e-03,  2.89744269e-02, -2.42981911e-01,\n",
       "       -1.70941129e-01, -4.82342998e-03, -7.02783524e-04, -2.27740273e-01,\n",
       "       -1.72800973e-01, -1.27308769e-02,  2.30893269e-01,  5.35238646e-02,\n",
       "        2.12870557e-02, -2.04236358e-02,  1.89132676e-01, -3.94848846e-02,\n",
       "       -9.10040215e-02,  8.92355889e-02, -8.18222985e-02,  5.58757745e-02,\n",
       "       -1.68974504e-01,  8.49855766e-02, -1.11382507e-01, -2.90302545e-01,\n",
       "       -1.41914003e-02,  1.59132093e-01,  1.47715062e-01,  1.86919793e-02,\n",
       "        1.17414370e-02, -2.07834274e-01,  9.61286109e-03, -2.32022703e-02,\n",
       "       -2.77668417e-01, -1.88603811e-02,  8.91737118e-02, -1.35947511e-01,\n",
       "       -2.02856469e-03,  5.49693219e-02, -1.85341276e-02,  1.12926140e-01,\n",
       "        2.81556338e-01, -2.84257472e-01, -1.23987757e-01,  1.02725185e-01,\n",
       "       -8.62205848e-02,  6.02735057e-02, -1.84652172e-02,  1.20814472e-01,\n",
       "       -1.37859618e-03,  9.45790857e-02,  8.14568549e-02,  1.92121565e-02,\n",
       "       -8.94231070e-03, -2.14111477e-01, -3.16160232e-01, -1.86573546e-02,\n",
       "       -6.90883473e-02, -1.30010962e-01, -4.10868563e-02, -3.07481170e-01,\n",
       "        1.20066963e-01, -2.37131715e-01,  8.13767463e-02,  1.88772812e-01,\n",
       "       -6.05665632e-02, -1.24549434e-01, -2.61325985e-01,  1.30334273e-01,\n",
       "       -1.18466467e-01, -1.27582431e-01, -2.44454630e-02, -8.85202289e-02,\n",
       "        1.03244200e-01, -8.08538646e-02,  1.12906374e-01,  3.43279615e-02,\n",
       "       -8.71110782e-02, -1.14432700e-01, -1.20910279e-01,  8.83991271e-03,\n",
       "       -3.71200661e-03,  1.67150963e-02, -1.76827371e-01,  1.04882397e-01,\n",
       "        1.02952151e-02,  2.94985712e-01, -5.62091358e-02, -1.93675801e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec[\"<unk>\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_embeddings = torch.from_numpy(np.stack(list(map(navec.get, navec.vocab.words[:-2]))))\n",
    "navec_embeddings = torch.nn.functional.normalize(navec_embeddings, dim=-1)\n",
    "\n",
    "idx_to_word = dict(enumerate(navec.vocab.words[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(word: str | torch.Tensor, top_k=5):\n",
    "    if isinstance(word, str):\n",
    "        embedding = torch.nn.functional.normalize(torch.from_numpy(navec[word]), dim=0)\n",
    "    else:\n",
    "        embedding = word\n",
    "    \n",
    "    sim = embedding @ navec_embeddings.T\n",
    "    idx = sim.topk(top_k + 1).indices\n",
    "\n",
    "    top_sim = sim[idx][1:].tolist()\n",
    "    top_words = [idx_to_word[i] for i in idx.tolist()[1:]]\n",
    "\n",
    "    return pd.DataFrame(zip(top_words, top_sim), columns=[\"word\", \"similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кошка</td>\n",
       "      <td>0.671421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>котенок</td>\n",
       "      <td>0.656233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>пес</td>\n",
       "      <td>0.650454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кота</td>\n",
       "      <td>0.646174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>рыжий</td>\n",
       "      <td>0.611956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  similarity\n",
       "0    кошка    0.671421\n",
       "1  котенок    0.656233\n",
       "2      пес    0.650454\n",
       "3     кота    0.646174\n",
       "4    рыжий    0.611956"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest(\"кот\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>дождик</td>\n",
       "      <td>0.670390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>моросящий</td>\n",
       "      <td>0.615993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>дождичек</td>\n",
       "      <td>0.612513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>моросил</td>\n",
       "      <td>0.574571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>дождь</td>\n",
       "      <td>0.557204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  similarity\n",
       "0     дождик    0.670390\n",
       "1  моросящий    0.615993\n",
       "2   дождичек    0.612513\n",
       "3    моросил    0.574571\n",
       "4      дождь    0.557204"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest(\"мелкий\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_after_math(main, sub, add):\n",
    "    final_vec = torch.from_numpy(navec[main] - navec[sub] + navec[add])\n",
    "    final_vec = torch.nn.functional.normalize(final_vec, dim=0)\n",
    "\n",
    "    return find_closest(final_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>королева</td>\n",
       "      <td>0.739691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>принцесса</td>\n",
       "      <td>0.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>короля</td>\n",
       "      <td>0.624119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>королю</td>\n",
       "      <td>0.583482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>величество</td>\n",
       "      <td>0.568573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  similarity\n",
       "0    королева    0.739691\n",
       "1   принцесса    0.627000\n",
       "2      короля    0.624119\n",
       "3      королю    0.583482\n",
       "4  величество    0.568573"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_after_math(\"король\", \"мужчина\", \"женщина\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>россия</td>\n",
       "      <td>0.647118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>америка</td>\n",
       "      <td>0.622991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>европа</td>\n",
       "      <td>0.610933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>страна</td>\n",
       "      <td>0.580128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>советская</td>\n",
       "      <td>0.543572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  similarity\n",
       "0     россия    0.647118\n",
       "1    америка    0.622991\n",
       "2     европа    0.610933\n",
       "3     страна    0.580128\n",
       "4  советская    0.543572"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_after_math(\"америка\", \"вашингтон\", \"москва\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### За и против"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Плюсы\n",
    "- Репрезентации слов, понимающие отношения и характеристики реального мира\n",
    "- Можно брать и использовать!\n",
    "\n",
    "#### Минусы\n",
    "- Неинтерпретируемы\n",
    "- Есть проблемы с разными значениями слов\n",
    "- Есть out-of-vocabulary слова: новые слова, редкие слова, опечатки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Козыри"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что если брать эмбеддинги последовательностей букв?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/fasttext.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема с out-of-vocabulary частично решается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть по вектору для каждого слова. Как будем получать вектор предложения для классификации?\n",
    "\n",
    "<img src=\"attachements/first/w2v_agg_question.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/w2v_agg.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text: list[str], mean=True) -> np.ndarray:\n",
    "    embeddings = [navec.get(x, navec['<unk>']) for x in text]\n",
    "    \n",
    "    if mean:\n",
    "        return np.stack(embeddings).mean(axis=0)\n",
    "    else:\n",
    "        return np.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(train_data[\"processed_text\"].apply(vectorize))\n",
    "X_test = np.stack(test_data[\"processed_text\"].apply(vectorize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17153, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = logreg.predict(X_train)\n",
    "pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision = 0.7809, Recall = 0.7689, F1 = 0.7734\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(y_train, pred_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision = 0.7412, Recall = 0.7325, F1 = 0.7360\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(y_test, pred_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слабовато, правда? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recurrent Neural Networks** (рекуррентные нейронные сети)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/rnn_basic.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/stack_more.webp\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/rnn_multilayer.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/bidirectional_rnn.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/vanilla_cell.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachements/first/lstm_cell.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё GRU - она как LSTM, только попроще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = train_data[\"processed_text\"].str.len().sort_values().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.loc[sorted_idx]\n",
    "y_train = train_data[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[\"processed_text\"].values\n",
    "X_test = test_data[\"processed_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aleksiej/projects/nlp_lectures/pre_ptransformers.ipynb Cell 168\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/pre_ptransformers.ipynb#Y250sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m counts \u001b[39m=\u001b[39m Counter(reduce(\u001b[39mlambda\u001b[39;00m x, y: x \u001b[39m+\u001b[39m y, X_train))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/pre_ptransformers.ipynb#Y250sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m counts\u001b[39m.\u001b[39mmost_common(\u001b[39m10000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "counts = Counter(reduce(lambda x, y: x + y, X_train))\n",
    "counts.most_common(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26735"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aleksiej/projects/nlp_lectures/pre_ptransformers.ipynb Cell 170\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aleksiej/projects/nlp_lectures/pre_ptransformers.ipynb#Y252sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m word_dist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(counts)\u001b[39m.\u001b[39msort_values(ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mhead(\u001b[39m150\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'counts' is not defined"
     ]
    }
   ],
   "source": [
    "word_dist = pd.Series(counts).sort_values(ascending=False).head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_dist.plot.area(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsums = (word_dist / counts.total()).cumsum().reset_index(name=\"cumsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cumsums.query(\"cumsum <= 0.50\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10479\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(cumsums.query(\"cumsum <= 0.9\")) \n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"<UNK>\"] + cumsums[\"index\"].iloc[0:vocab_size].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EMBEDDING_SIZE = 300\n",
    "HIDDEN_SIZE = 300\n",
    "NUM_CLASSES = 4\n",
    "NUM_EPOCHS = 5\n",
    "NUM_LAYERS = 3\n",
    "LEARNING_RATE = 5e-3\n",
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLstmForClassification(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=True, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.ff = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "        self.embedding = None\n",
    "        self._word2idx = None\n",
    "        self._embed = None\n",
    "\n",
    "    def forward(self, texts):\n",
    "        if self._embed is None:\n",
    "            raise NotImplementedError(\"You forgot to init embeddings.\")\n",
    "\n",
    "        embeddings = self._embed(texts)\n",
    "        embeddings = self._prepare_embeddings(embeddings)\n",
    "\n",
    "        out, (hidden, cell) = self.lstm(embeddings)\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "\n",
    "        return self.ff(hidden)\n",
    "\n",
    "    def init_embeddings(self, learn_embeddings, **kwargs):\n",
    "        if learn_embeddings:\n",
    "            self._word2idx = kwargs[\"word2idx\"]\n",
    "\n",
    "            embedding_matrix = self._init_embedding_matrix()\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "            self._embed = self._embed_self\n",
    "        else:\n",
    "            self._embed = self._embed_navec\n",
    "    \n",
    "    def _init_embedding_matrix(self):\n",
    "        vocab_size = len(self._word2idx)\n",
    "        init_matrix = np.random.rand(vocab_size, self.emb_size)\n",
    "\n",
    "        for word, idx in self._word2idx.items():\n",
    "            navec_emb = navec.get(word)\n",
    "            if navec_emb is not None:\n",
    "                init_matrix[idx] = navec_emb\n",
    "        \n",
    "        return torch.from_numpy(init_matrix).to(torch.float32)\n",
    "\n",
    "    def _embed_self(self, texts: list[list[str]]) -> list[torch.Tensor]:\n",
    "        ids = list(map(self._convert_words2idx, texts))\n",
    "        embeddings = list(map(self.embedding, ids))\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def _convert_words2idx(self, text: list[str]) -> list[int]:\n",
    "        encoded = [self._word2idx.get(w, self._word2idx[\"<UNK>\"]) for w in text]\n",
    "        return torch.tensor(encoded, dtype=torch.int)\n",
    "\n",
    "    @staticmethod\n",
    "    def _embed_navec(texts: list[list[str]]) -> list[torch.Tensor]:\n",
    "        embeddings = list(map(partial(vectorize, mean=False), texts))\n",
    "        embeddings = list(map(torch.from_numpy, embeddings))\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_embeddings(embeddings: list[torch.Tensor]):\n",
    "        lengths = list(map(len, embeddings))\n",
    "\n",
    "        embeddings = nn.utils.rnn.pad_sequence(embeddings, batch_first=True)\n",
    "        embeddings = nn.utils.rnn.pack_padded_sequence(\n",
    "            embeddings, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        return embeddings.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    texts = list(map(itemgetter(0), batch))\n",
    "    labels = list(map(itemgetter(1), batch))\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LstmDataset(X_train, y_train)\n",
    "test_dataset = LstmDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLstmForClassification(\n",
       "  (lstm): LSTM(300, 300, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (ff): Linear(in_features=600, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = BiLstmForClassification(EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES)\n",
    "lstm.init_embeddings(learn_embeddings=False, word2idx=word2idx)\n",
    "lstm.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksiej/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    lstm.train()\n",
    "\n",
    "    losses = []\n",
    "    for texts, labels in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = lstm(texts)\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_epoch():\n",
    "    lstm.eval()\n",
    "\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    for texts, labels in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = lstm(texts)\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "        pred_labels = outputs.argmax(dim=1).tolist()\n",
    "\n",
    "        predictions.extend(pred_labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    \n",
    "    return epoch_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_epoch()\n",
    "        test_loss, pred_test = test_epoch()\n",
    "\n",
    "        print(f\"TRAIN Epoch {epoch+1}, Loss: {train_loss:.4f}\")\n",
    "        print(f\"TEST Epoch {epoch+1}, Loss: {test_loss:.4f}\")\n",
    "\n",
    "        compute_metrics(y_test, pred_test)\n",
    "        print()\n",
    "    \n",
    "    return pred_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:31<00:00,  1.84s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 1, Loss: 1.1479\n",
      "TEST Epoch 1, Loss: 0.8183\n",
      "Macro Precision = 0.7066, Recall = 0.6819, F1 = 0.6846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:28<00:00,  1.68s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 2, Loss: 0.7020\n",
      "TEST Epoch 2, Loss: 0.7368\n",
      "Macro Precision = 0.7478, Recall = 0.7562, F1 = 0.7491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:28<00:00,  1.69s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 3, Loss: 0.5903\n",
      "TEST Epoch 3, Loss: 0.5957\n",
      "Macro Precision = 0.8003, Recall = 0.7702, F1 = 0.7804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:29<00:00,  1.74s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 4, Loss: 0.5277\n",
      "TEST Epoch 4, Loss: 0.6012\n",
      "Macro Precision = 0.7851, Recall = 0.7864, F1 = 0.7819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:30<00:00,  1.78s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 5, Loss: 0.4901\n",
      "TEST Epoch 5, Loss: 0.6092\n",
      "Macro Precision = 0.8117, Recall = 0.7643, F1 = 0.7757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLstmForClassification(\n",
       "  (lstm): LSTM(300, 300, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (ff): Linear(in_features=600, out_features=4, bias=True)\n",
       "  (embedding): Embedding(10480, 300)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = BiLstmForClassification(EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES)\n",
    "lstm.init_embeddings(learn_embeddings=True, word2idx=word2idx)\n",
    "lstm.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:12<00:00,  4.26s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 1, Loss: 1.1721\n",
      "TEST Epoch 1, Loss: 0.7878\n",
      "Macro Precision = 0.7737, Recall = 0.6746, F1 = 0.6839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:19<00:00,  4.65s/it]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 2, Loss: 0.5975\n",
      "TEST Epoch 2, Loss: 0.6124\n",
      "Macro Precision = 0.7741, Recall = 0.7895, F1 = 0.7678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:12<00:00,  4.27s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 3, Loss: 0.3817\n",
      "TEST Epoch 3, Loss: 0.5007\n",
      "Macro Precision = 0.8417, Recall = 0.8158, F1 = 0.8244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:56<00:00,  3.31s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 4, Loss: 0.2498\n",
      "TEST Epoch 4, Loss: 0.5869\n",
      "Macro Precision = 0.8119, Recall = 0.8201, F1 = 0.8013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:04<00:00,  3.79s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 5, Loss: 0.1808\n",
      "TEST Epoch 5, Loss: 0.5399\n",
      "Macro Precision = 0.8547, Recall = 0.8320, F1 = 0.8397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Круто!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### НО не нужно забывать базу!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классика любого прода: строим бейзлайн на TF-IDF (на стероидах) + SVM за пол дня, а затем пытаемся побить его SOTA-моделями всей командой два месяца."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
